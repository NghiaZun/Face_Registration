/****************************************************************************
*   Generated by ACUITY 6.30.0
*   Match ovxlib 1.1.53
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_minifasnetv1se.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        if( NULL == _node ) {\
            goto error;\
        }\
        _node->uid = (uint32_t)_uid;\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(vsi_size_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        if( NULL == data ) {\
            goto error;\
        }\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        if ( enable_from_handle )\
        {\
            _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                    & _attr, NULL );\
        }\
        else\
        {\
            _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                    & _attr, NULL );\
        }\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR_FROM_HANDLE(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (115)
#define NET_NORM_TENSOR_NUM     (2)
#define NET_CONST_TENSOR_NUM    (147)
#define NET_VIRTUAL_TENSOR_NUM  (115)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    ssize_t ret;
    size_t size;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = VSI_FSEEK(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    size = fread(data, 1, sz, fp);
    if (size != sz || size == 0)
    {
        free(data);
        data = NULL;
        VSILOGE("Read file to buffer failed.");
    }
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateMinifasnetv1se
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx,
    const vsi_nn_preprocess_map_element_t * pre_process_map,
    uint32_t pre_process_map_count,
    const vsi_nn_postprocess_map_element_t * post_process_map,
    uint32_t post_process_map_count
    )
{
    uint32_t                _infinity = VSI_NN_FLOAT32_INF;
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;
    uint32_t                i = 0;
    char *                  use_img_process_s;
    char *                  use_from_handle = NULL;
    int32_t                 enable_pre_post_process = 0;
    int32_t                 enable_from_handle = 0;
    vsi_bool                sort = FALSE;
    vsi_bool                inference_with_nbg = FALSE;
    char*                   pos = NULL;

    vsi_size_t shape_1[] = { -1, 1 };




    (void)(_infinity);
    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;
    memset( &attr, 0, sizeof( attr ) );
    memset( &node, 0, sizeof( vsi_nn_node_t * ) * NET_NODE_NUM );

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    pos = strstr(data_file_name, ".nb");
    if( pos && strcmp(pos, ".nb") == 0 )
    {
        inference_with_nbg = TRUE;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
    }
    else
    {
        ctx = in_ctx;
    }

    use_img_process_s = getenv( "VSI_USE_IMAGE_PROCESS" );
    if( use_img_process_s )
    {
        enable_pre_post_process = atoi(use_img_process_s);
    }
    use_from_handle = getenv( "VSI_USE_FROM_HANDLE" );
    if ( use_from_handle )
    {
        enable_from_handle = atoi(use_from_handle);
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphVersion( graph, VNN_VERSION_MAJOR, VNN_VERSION_MINOR, VNN_VERSION_PATCH );
    vsi_nn_SetGraphInputs( graph, NULL, 1 );
    vsi_nn_SetGraphOutputs( graph, NULL, 1 );
    vsi_nn_SetGraphFastMode(graph,FALSE);

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/
    if( !inference_with_nbg )
    {

    /*-----------------------------------------
      lid       - conv1/conv/Conv_output_0_116
      var       - node[0]
      name      - conv1/conv/Conv_output_0
      operation - convolution
      input     - [80, 80, 3, 1]
      filter    - [3, 3, 3, 32]
      output    - [40, 40, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_CONV2D, 3, 1, 116);
    node[0]->nn_param.conv2d.ksize[0] = 3;
    node[0]->nn_param.conv2d.ksize[1] = 3;
    node[0]->nn_param.conv2d.weights = 32;
    node[0]->nn_param.conv2d.stride[0] = 2;
    node[0]->nn_param.conv2d.stride[1] = 2;
    node[0]->nn_param.conv2d.pad[0] = 1;
    node[0]->nn_param.conv2d.pad[1] = 1;
    node[0]->nn_param.conv2d.pad[2] = 1;
    node[0]->nn_param.conv2d.pad[3] = 1;
    node[0]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[0]->nn_param.conv2d.group = 1;
    node[0]->nn_param.conv2d.dilation[0] = 1;
    node[0]->nn_param.conv2d.dilation[1] = 1;
    node[0]->nn_param.conv2d.multiplier = 0;
    node[0]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[0]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[0]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv1/prelu/PRelu_output_0_115
      var       - node[1]
      name      - conv1/prelu/PRelu_output_0
      operation - prelu
      input     - [40, 40, 32, 1]
      output    - [40, 40, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_PRELU, 2, 1, 115);

    /*-----------------------------------------
      lid       - conv2_dw/conv/Conv_output_0_114
      var       - node[2]
      name      - conv2_dw/conv/Conv_output_0
      operation - convolution
      input     - [40, 40, 32, 1]
      filter    - [3, 3, 32, 1]
      output    - [40, 40, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_CONV2D, 3, 1, 114);
    node[2]->nn_param.conv2d.ksize[0] = 3;
    node[2]->nn_param.conv2d.ksize[1] = 3;
    node[2]->nn_param.conv2d.weights = 32;
    node[2]->nn_param.conv2d.stride[0] = 1;
    node[2]->nn_param.conv2d.stride[1] = 1;
    node[2]->nn_param.conv2d.pad[0] = 1;
    node[2]->nn_param.conv2d.pad[1] = 1;
    node[2]->nn_param.conv2d.pad[2] = 1;
    node[2]->nn_param.conv2d.pad[3] = 1;
    node[2]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[2]->nn_param.conv2d.group = 32;
    node[2]->nn_param.conv2d.dilation[0] = 1;
    node[2]->nn_param.conv2d.dilation[1] = 1;
    node[2]->nn_param.conv2d.multiplier = 1;
    node[2]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[2]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[2]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv2_dw/prelu/PRelu_output_0_113
      var       - node[3]
      name      - conv2_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [40, 40, 32, 1]
      output    - [40, 40, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_PRELU, 2, 1, 113);

    /*-----------------------------------------
      lid       - conv_23/conv/conv/Conv_output_0_112
      var       - node[4]
      name      - conv_23/conv/conv/Conv_output_0
      operation - convolution
      input     - [40, 40, 32, 1]
      filter    - [1, 1, 32, 103]
      output    - [40, 40, 103, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_CONV2D, 3, 1, 112);
    node[4]->nn_param.conv2d.ksize[0] = 1;
    node[4]->nn_param.conv2d.ksize[1] = 1;
    node[4]->nn_param.conv2d.weights = 103;
    node[4]->nn_param.conv2d.stride[0] = 1;
    node[4]->nn_param.conv2d.stride[1] = 1;
    node[4]->nn_param.conv2d.pad[0] = 0;
    node[4]->nn_param.conv2d.pad[1] = 0;
    node[4]->nn_param.conv2d.pad[2] = 0;
    node[4]->nn_param.conv2d.pad[3] = 0;
    node[4]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[4]->nn_param.conv2d.group = 1;
    node[4]->nn_param.conv2d.dilation[0] = 1;
    node[4]->nn_param.conv2d.dilation[1] = 1;
    node[4]->nn_param.conv2d.multiplier = 0;
    node[4]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[4]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[4]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_23/conv/prelu/PRelu_output_0_108
      var       - node[5]
      name      - conv_23/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [40, 40, 103, 1]
      output    - [40, 40, 103, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_PRELU, 2, 1, 108);

    /*-----------------------------------------
      lid       - conv_23/conv_dw/conv/Conv_output_0_102
      var       - node[6]
      name      - conv_23/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [40, 40, 103, 1]
      filter    - [3, 3, 103, 1]
      output    - [20, 20, 103, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_CONV2D, 3, 1, 102);
    node[6]->nn_param.conv2d.ksize[0] = 3;
    node[6]->nn_param.conv2d.ksize[1] = 3;
    node[6]->nn_param.conv2d.weights = 103;
    node[6]->nn_param.conv2d.stride[0] = 2;
    node[6]->nn_param.conv2d.stride[1] = 2;
    node[6]->nn_param.conv2d.pad[0] = 1;
    node[6]->nn_param.conv2d.pad[1] = 1;
    node[6]->nn_param.conv2d.pad[2] = 1;
    node[6]->nn_param.conv2d.pad[3] = 1;
    node[6]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[6]->nn_param.conv2d.group = 103;
    node[6]->nn_param.conv2d.dilation[0] = 1;
    node[6]->nn_param.conv2d.dilation[1] = 1;
    node[6]->nn_param.conv2d.multiplier = 1;
    node[6]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[6]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[6]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_23/conv_dw/prelu/PRelu_output_0_96
      var       - node[7]
      name      - conv_23/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 103, 1]
      output    - [20, 20, 103, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_PRELU, 2, 1, 96);

    /*-----------------------------------------
      lid       - conv_23/project/conv/Conv_output_0_90
      var       - node[8]
      name      - conv_23/project/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 103, 1]
      filter    - [1, 1, 103, 64]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_CONV2D, 3, 1, 90);
    node[8]->nn_param.conv2d.ksize[0] = 1;
    node[8]->nn_param.conv2d.ksize[1] = 1;
    node[8]->nn_param.conv2d.weights = 64;
    node[8]->nn_param.conv2d.stride[0] = 1;
    node[8]->nn_param.conv2d.stride[1] = 1;
    node[8]->nn_param.conv2d.pad[0] = 0;
    node[8]->nn_param.conv2d.pad[1] = 0;
    node[8]->nn_param.conv2d.pad[2] = 0;
    node[8]->nn_param.conv2d.pad[3] = 0;
    node[8]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[8]->nn_param.conv2d.group = 1;
    node[8]->nn_param.conv2d.dilation[0] = 1;
    node[8]->nn_param.conv2d.dilation[1] = 1;
    node[8]->nn_param.conv2d.multiplier = 0;
    node[8]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[8]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[8]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/0/conv/conv/Conv_output_0_111
      var       - node[9]
      name      - conv_3/model/0/conv/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 64, 1]
      filter    - [1, 1, 64, 13]
      output    - [20, 20, 13, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_CONV2D, 3, 1, 111);
    node[9]->nn_param.conv2d.ksize[0] = 1;
    node[9]->nn_param.conv2d.ksize[1] = 1;
    node[9]->nn_param.conv2d.weights = 13;
    node[9]->nn_param.conv2d.stride[0] = 1;
    node[9]->nn_param.conv2d.stride[1] = 1;
    node[9]->nn_param.conv2d.pad[0] = 0;
    node[9]->nn_param.conv2d.pad[1] = 0;
    node[9]->nn_param.conv2d.pad[2] = 0;
    node[9]->nn_param.conv2d.pad[3] = 0;
    node[9]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[9]->nn_param.conv2d.group = 1;
    node[9]->nn_param.conv2d.dilation[0] = 1;
    node[9]->nn_param.conv2d.dilation[1] = 1;
    node[9]->nn_param.conv2d.multiplier = 0;
    node[9]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[9]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[9]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/0/conv/prelu/PRelu_output_0_109
      var       - node[10]
      name      - conv_3/model/0/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 13, 1]
      output    - [20, 20, 13, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_PRELU, 2, 1, 109);

    /*-----------------------------------------
      lid       - conv_3/model/0/conv_dw/conv/Conv_output_0_103
      var       - node[11]
      name      - conv_3/model/0/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 13, 1]
      filter    - [3, 3, 13, 1]
      output    - [20, 20, 13, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_CONV2D, 3, 1, 103);
    node[11]->nn_param.conv2d.ksize[0] = 3;
    node[11]->nn_param.conv2d.ksize[1] = 3;
    node[11]->nn_param.conv2d.weights = 13;
    node[11]->nn_param.conv2d.stride[0] = 1;
    node[11]->nn_param.conv2d.stride[1] = 1;
    node[11]->nn_param.conv2d.pad[0] = 1;
    node[11]->nn_param.conv2d.pad[1] = 1;
    node[11]->nn_param.conv2d.pad[2] = 1;
    node[11]->nn_param.conv2d.pad[3] = 1;
    node[11]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[11]->nn_param.conv2d.group = 13;
    node[11]->nn_param.conv2d.dilation[0] = 1;
    node[11]->nn_param.conv2d.dilation[1] = 1;
    node[11]->nn_param.conv2d.multiplier = 1;
    node[11]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[11]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[11]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/0/conv_dw/prelu/PRelu_output_0_97
      var       - node[12]
      name      - conv_3/model/0/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 13, 1]
      output    - [20, 20, 13, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_PRELU, 2, 1, 97);

    /*-----------------------------------------
      lid       - conv_3/model/0/project/conv/Conv_output_0_91
      var       - node[13]
      name      - conv_3/model/0/project/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 13, 1]
      filter    - [1, 1, 13, 64]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_CONV2D, 3, 1, 91);
    node[13]->nn_param.conv2d.ksize[0] = 1;
    node[13]->nn_param.conv2d.ksize[1] = 1;
    node[13]->nn_param.conv2d.weights = 64;
    node[13]->nn_param.conv2d.stride[0] = 1;
    node[13]->nn_param.conv2d.stride[1] = 1;
    node[13]->nn_param.conv2d.pad[0] = 0;
    node[13]->nn_param.conv2d.pad[1] = 0;
    node[13]->nn_param.conv2d.pad[2] = 0;
    node[13]->nn_param.conv2d.pad[3] = 0;
    node[13]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[13]->nn_param.conv2d.group = 1;
    node[13]->nn_param.conv2d.dilation[0] = 1;
    node[13]->nn_param.conv2d.dilation[1] = 1;
    node[13]->nn_param.conv2d.multiplier = 0;
    node[13]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[13]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[13]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/0/Add_output_0_85
      var       - node[14]
      name      - conv_3/model/0/Add_output_0
      operation - add
      input     - [20, 20, 64, 1]
                  [20, 20, 64, 1]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_ADD, 2, 1, 85);

    /*-----------------------------------------
      lid       - conv_3/model/1/conv/conv/Conv_output_0_110
      var       - node[15]
      name      - conv_3/model/1/conv/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 64, 1]
      filter    - [1, 1, 64, 26]
      output    - [20, 20, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_CONV2D, 3, 1, 110);
    node[15]->nn_param.conv2d.ksize[0] = 1;
    node[15]->nn_param.conv2d.ksize[1] = 1;
    node[15]->nn_param.conv2d.weights = 26;
    node[15]->nn_param.conv2d.stride[0] = 1;
    node[15]->nn_param.conv2d.stride[1] = 1;
    node[15]->nn_param.conv2d.pad[0] = 0;
    node[15]->nn_param.conv2d.pad[1] = 0;
    node[15]->nn_param.conv2d.pad[2] = 0;
    node[15]->nn_param.conv2d.pad[3] = 0;
    node[15]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[15]->nn_param.conv2d.group = 1;
    node[15]->nn_param.conv2d.dilation[0] = 1;
    node[15]->nn_param.conv2d.dilation[1] = 1;
    node[15]->nn_param.conv2d.multiplier = 0;
    node[15]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[15]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[15]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/1/conv/prelu/PRelu_output_0_104
      var       - node[16]
      name      - conv_3/model/1/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 26, 1]
      output    - [20, 20, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_PRELU, 2, 1, 104);

    /*-----------------------------------------
      lid       - conv_3/model/1/conv_dw/conv/Conv_output_0_98
      var       - node[17]
      name      - conv_3/model/1/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 26, 1]
      filter    - [3, 3, 26, 1]
      output    - [20, 20, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_CONV2D, 3, 1, 98);
    node[17]->nn_param.conv2d.ksize[0] = 3;
    node[17]->nn_param.conv2d.ksize[1] = 3;
    node[17]->nn_param.conv2d.weights = 26;
    node[17]->nn_param.conv2d.stride[0] = 1;
    node[17]->nn_param.conv2d.stride[1] = 1;
    node[17]->nn_param.conv2d.pad[0] = 1;
    node[17]->nn_param.conv2d.pad[1] = 1;
    node[17]->nn_param.conv2d.pad[2] = 1;
    node[17]->nn_param.conv2d.pad[3] = 1;
    node[17]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[17]->nn_param.conv2d.group = 26;
    node[17]->nn_param.conv2d.dilation[0] = 1;
    node[17]->nn_param.conv2d.dilation[1] = 1;
    node[17]->nn_param.conv2d.multiplier = 1;
    node[17]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[17]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[17]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/1/conv_dw/prelu/PRelu_output_0_92
      var       - node[18]
      name      - conv_3/model/1/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 26, 1]
      output    - [20, 20, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_PRELU, 2, 1, 92);

    /*-----------------------------------------
      lid       - conv_3/model/1/project/conv/Conv_output_0_86
      var       - node[19]
      name      - conv_3/model/1/project/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 26, 1]
      filter    - [1, 1, 26, 64]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_CONV2D, 3, 1, 86);
    node[19]->nn_param.conv2d.ksize[0] = 1;
    node[19]->nn_param.conv2d.ksize[1] = 1;
    node[19]->nn_param.conv2d.weights = 64;
    node[19]->nn_param.conv2d.stride[0] = 1;
    node[19]->nn_param.conv2d.stride[1] = 1;
    node[19]->nn_param.conv2d.pad[0] = 0;
    node[19]->nn_param.conv2d.pad[1] = 0;
    node[19]->nn_param.conv2d.pad[2] = 0;
    node[19]->nn_param.conv2d.pad[3] = 0;
    node[19]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[19]->nn_param.conv2d.group = 1;
    node[19]->nn_param.conv2d.dilation[0] = 1;
    node[19]->nn_param.conv2d.dilation[1] = 1;
    node[19]->nn_param.conv2d.multiplier = 0;
    node[19]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[19]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[19]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/1/Add_output_0_81
      var       - node[20]
      name      - conv_3/model/1/Add_output_0
      operation - add
      input     - [20, 20, 64, 1]
                  [20, 20, 64, 1]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_ADD, 2, 1, 81);

    /*-----------------------------------------
      lid       - conv_3/model/2/conv/conv/Conv_output_0_105
      var       - node[21]
      name      - conv_3/model/2/conv/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 64, 1]
      filter    - [1, 1, 64, 13]
      output    - [20, 20, 13, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_CONV2D, 3, 1, 105);
    node[21]->nn_param.conv2d.ksize[0] = 1;
    node[21]->nn_param.conv2d.ksize[1] = 1;
    node[21]->nn_param.conv2d.weights = 13;
    node[21]->nn_param.conv2d.stride[0] = 1;
    node[21]->nn_param.conv2d.stride[1] = 1;
    node[21]->nn_param.conv2d.pad[0] = 0;
    node[21]->nn_param.conv2d.pad[1] = 0;
    node[21]->nn_param.conv2d.pad[2] = 0;
    node[21]->nn_param.conv2d.pad[3] = 0;
    node[21]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[21]->nn_param.conv2d.group = 1;
    node[21]->nn_param.conv2d.dilation[0] = 1;
    node[21]->nn_param.conv2d.dilation[1] = 1;
    node[21]->nn_param.conv2d.multiplier = 0;
    node[21]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[21]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[21]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/2/conv/prelu/PRelu_output_0_99
      var       - node[22]
      name      - conv_3/model/2/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 13, 1]
      output    - [20, 20, 13, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_PRELU, 2, 1, 99);

    /*-----------------------------------------
      lid       - conv_3/model/2/conv_dw/conv/Conv_output_0_93
      var       - node[23]
      name      - conv_3/model/2/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 13, 1]
      filter    - [3, 3, 13, 1]
      output    - [20, 20, 13, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_CONV2D, 3, 1, 93);
    node[23]->nn_param.conv2d.ksize[0] = 3;
    node[23]->nn_param.conv2d.ksize[1] = 3;
    node[23]->nn_param.conv2d.weights = 13;
    node[23]->nn_param.conv2d.stride[0] = 1;
    node[23]->nn_param.conv2d.stride[1] = 1;
    node[23]->nn_param.conv2d.pad[0] = 1;
    node[23]->nn_param.conv2d.pad[1] = 1;
    node[23]->nn_param.conv2d.pad[2] = 1;
    node[23]->nn_param.conv2d.pad[3] = 1;
    node[23]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[23]->nn_param.conv2d.group = 13;
    node[23]->nn_param.conv2d.dilation[0] = 1;
    node[23]->nn_param.conv2d.dilation[1] = 1;
    node[23]->nn_param.conv2d.multiplier = 1;
    node[23]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[23]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[23]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/2/conv_dw/prelu/PRelu_output_0_87
      var       - node[24]
      name      - conv_3/model/2/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 13, 1]
      output    - [20, 20, 13, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_PRELU, 2, 1, 87);

    /*-----------------------------------------
      lid       - conv_3/model/2/project/conv/Conv_output_0_82
      var       - node[25]
      name      - conv_3/model/2/project/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 13, 1]
      filter    - [1, 1, 13, 64]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_CONV2D, 3, 1, 82);
    node[25]->nn_param.conv2d.ksize[0] = 1;
    node[25]->nn_param.conv2d.ksize[1] = 1;
    node[25]->nn_param.conv2d.weights = 64;
    node[25]->nn_param.conv2d.stride[0] = 1;
    node[25]->nn_param.conv2d.stride[1] = 1;
    node[25]->nn_param.conv2d.pad[0] = 0;
    node[25]->nn_param.conv2d.pad[1] = 0;
    node[25]->nn_param.conv2d.pad[2] = 0;
    node[25]->nn_param.conv2d.pad[3] = 0;
    node[25]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[25]->nn_param.conv2d.group = 1;
    node[25]->nn_param.conv2d.dilation[0] = 1;
    node[25]->nn_param.conv2d.dilation[1] = 1;
    node[25]->nn_param.conv2d.multiplier = 0;
    node[25]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[25]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[25]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/2/Add_output_0_79
      var       - node[26]
      name      - conv_3/model/2/Add_output_0
      operation - add
      input     - [20, 20, 64, 1]
                  [20, 20, 64, 1]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_ADD, 2, 1, 79);

    /*-----------------------------------------
      lid       - conv_3/model/3/conv/conv/Conv_output_0_106
      var       - node[27]
      name      - conv_3/model/3/conv/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 64, 1]
      filter    - [1, 1, 64, 52]
      output    - [20, 20, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_CONV2D, 3, 1, 106);
    node[27]->nn_param.conv2d.ksize[0] = 1;
    node[27]->nn_param.conv2d.ksize[1] = 1;
    node[27]->nn_param.conv2d.weights = 52;
    node[27]->nn_param.conv2d.stride[0] = 1;
    node[27]->nn_param.conv2d.stride[1] = 1;
    node[27]->nn_param.conv2d.pad[0] = 0;
    node[27]->nn_param.conv2d.pad[1] = 0;
    node[27]->nn_param.conv2d.pad[2] = 0;
    node[27]->nn_param.conv2d.pad[3] = 0;
    node[27]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[27]->nn_param.conv2d.group = 1;
    node[27]->nn_param.conv2d.dilation[0] = 1;
    node[27]->nn_param.conv2d.dilation[1] = 1;
    node[27]->nn_param.conv2d.multiplier = 0;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/3/conv/prelu/PRelu_output_0_100
      var       - node[28]
      name      - conv_3/model/3/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 52, 1]
      output    - [20, 20, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_PRELU, 2, 1, 100);

    /*-----------------------------------------
      lid       - conv_3/model/3/conv_dw/conv/Conv_output_0_94
      var       - node[29]
      name      - conv_3/model/3/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 52, 1]
      filter    - [3, 3, 52, 1]
      output    - [20, 20, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_CONV2D, 3, 1, 94);
    node[29]->nn_param.conv2d.ksize[0] = 3;
    node[29]->nn_param.conv2d.ksize[1] = 3;
    node[29]->nn_param.conv2d.weights = 52;
    node[29]->nn_param.conv2d.stride[0] = 1;
    node[29]->nn_param.conv2d.stride[1] = 1;
    node[29]->nn_param.conv2d.pad[0] = 1;
    node[29]->nn_param.conv2d.pad[1] = 1;
    node[29]->nn_param.conv2d.pad[2] = 1;
    node[29]->nn_param.conv2d.pad[3] = 1;
    node[29]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[29]->nn_param.conv2d.group = 52;
    node[29]->nn_param.conv2d.dilation[0] = 1;
    node[29]->nn_param.conv2d.dilation[1] = 1;
    node[29]->nn_param.conv2d.multiplier = 1;
    node[29]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[29]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[29]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/3/conv_dw/prelu/PRelu_output_0_88
      var       - node[30]
      name      - conv_3/model/3/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 52, 1]
      output    - [20, 20, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_PRELU, 2, 1, 88);

    /*-----------------------------------------
      lid       - conv_3/model/3/project/conv/Conv_output_0_83
      var       - node[31]
      name      - conv_3/model/3/project/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 52, 1]
      filter    - [1, 1, 52, 64]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_CONV2D, 3, 1, 83);
    node[31]->nn_param.conv2d.ksize[0] = 1;
    node[31]->nn_param.conv2d.ksize[1] = 1;
    node[31]->nn_param.conv2d.weights = 64;
    node[31]->nn_param.conv2d.stride[0] = 1;
    node[31]->nn_param.conv2d.stride[1] = 1;
    node[31]->nn_param.conv2d.pad[0] = 0;
    node[31]->nn_param.conv2d.pad[1] = 0;
    node[31]->nn_param.conv2d.pad[2] = 0;
    node[31]->nn_param.conv2d.pad[3] = 0;
    node[31]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[31]->nn_param.conv2d.group = 1;
    node[31]->nn_param.conv2d.dilation[0] = 1;
    node[31]->nn_param.conv2d.dilation[1] = 1;
    node[31]->nn_param.conv2d.multiplier = 0;
    node[31]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[31]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[31]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/3/se_module/avg_pool/GlobalAveragePool_output_0_107
      var       - node[32]
      name      - conv_3/model/3/se_module/avg_pool/GlobalAveragePool_output_0
      operation - pooling
      input     - [20, 20, 64, 1]
      output    - [1, 1, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_POOL, 1, 1, 107);
    node[32]->nn_param.pool.ksize[0] = 20;
    node[32]->nn_param.pool.ksize[1] = 20;
    node[32]->nn_param.pool.stride[0] = 1;
    node[32]->nn_param.pool.stride[1] = 1;
    node[32]->nn_param.pool.pad[0] = 0;
    node[32]->nn_param.pool.pad[1] = 0;
    node[32]->nn_param.pool.pad[2] = 0;
    node[32]->nn_param.pool.pad[3] = 0;
    node[32]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[32]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[32]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/3/se_module/fc1/Conv_output_0_101
      var       - node[33]
      name      - conv_3/model/3/se_module/fc1/Conv_output_0
      operation - convolution
      input     - [1, 1, 64, 1]
      filter    - [1, 1, 64, 16]
      output    - [1, 1, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[33], VSI_NN_OP_CONV2D, 3, 1, 101);
    node[33]->nn_param.conv2d.ksize[0] = 1;
    node[33]->nn_param.conv2d.ksize[1] = 1;
    node[33]->nn_param.conv2d.weights = 16;
    node[33]->nn_param.conv2d.stride[0] = 1;
    node[33]->nn_param.conv2d.stride[1] = 1;
    node[33]->nn_param.conv2d.pad[0] = 0;
    node[33]->nn_param.conv2d.pad[1] = 0;
    node[33]->nn_param.conv2d.pad[2] = 0;
    node[33]->nn_param.conv2d.pad[3] = 0;
    node[33]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[33]->nn_param.conv2d.group = 1;
    node[33]->nn_param.conv2d.dilation[0] = 1;
    node[33]->nn_param.conv2d.dilation[1] = 1;
    node[33]->nn_param.conv2d.multiplier = 0;
    node[33]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[33]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[33]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/3/se_module/relu/Relu_output_0_95
      var       - node[34]
      name      - conv_3/model/3/se_module/relu/Relu_output_0
      operation - relu
      input     - [1, 1, 16, 1]
      output    - [1, 1, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[34], VSI_NN_OP_RELU, 1, 1, 95);

    /*-----------------------------------------
      lid       - conv_3/model/3/se_module/fc2/Conv_output_0_89
      var       - node[35]
      name      - conv_3/model/3/se_module/fc2/Conv_output_0
      operation - convolution
      input     - [1, 1, 16, 1]
      filter    - [1, 1, 16, 64]
      output    - [1, 1, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[35], VSI_NN_OP_CONV2D, 3, 1, 89);
    node[35]->nn_param.conv2d.ksize[0] = 1;
    node[35]->nn_param.conv2d.ksize[1] = 1;
    node[35]->nn_param.conv2d.weights = 64;
    node[35]->nn_param.conv2d.stride[0] = 1;
    node[35]->nn_param.conv2d.stride[1] = 1;
    node[35]->nn_param.conv2d.pad[0] = 0;
    node[35]->nn_param.conv2d.pad[1] = 0;
    node[35]->nn_param.conv2d.pad[2] = 0;
    node[35]->nn_param.conv2d.pad[3] = 0;
    node[35]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[35]->nn_param.conv2d.group = 1;
    node[35]->nn_param.conv2d.dilation[0] = 1;
    node[35]->nn_param.conv2d.dilation[1] = 1;
    node[35]->nn_param.conv2d.multiplier = 0;
    node[35]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[35]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[35]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_3/model/3/se_module/sigmoid/Sigmoid_output_0_84
      var       - node[36]
      name      - conv_3/model/3/se_module/sigmoid/Sigmoid_output_0
      operation - sigmoid
      input     - [1, 1, 64, 1]
      output    - [1, 1, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[36], VSI_NN_OP_SIGMOID, 1, 1, 84);

    /*-----------------------------------------
      lid       - conv_3/model/3/se_module/Mul_output_0_80
      var       - node[37]
      name      - conv_3/model/3/se_module/Mul_output_0
      operation - multiply
      input     - [20, 20, 64, 1]
                  [1, 1, 64, 1]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[37], VSI_NN_OP_MULTIPLY, 2, 1, 80);
    node[37]->nn_param.multiply.scale = 1;
    node[37]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[37]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - conv_3/model/3/Add_output_0_78
      var       - node[38]
      name      - conv_3/model/3/Add_output_0
      operation - add
      input     - [20, 20, 64, 1]
                  [20, 20, 64, 1]
      output    - [20, 20, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[38], VSI_NN_OP_ADD, 2, 1, 78);

    /*-----------------------------------------
      lid       - conv_34/conv/conv/Conv_output_0_77
      var       - node[39]
      name      - conv_34/conv/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 64, 1]
      filter    - [1, 1, 64, 231]
      output    - [20, 20, 231, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[39], VSI_NN_OP_CONV2D, 3, 1, 77);
    node[39]->nn_param.conv2d.ksize[0] = 1;
    node[39]->nn_param.conv2d.ksize[1] = 1;
    node[39]->nn_param.conv2d.weights = 231;
    node[39]->nn_param.conv2d.stride[0] = 1;
    node[39]->nn_param.conv2d.stride[1] = 1;
    node[39]->nn_param.conv2d.pad[0] = 0;
    node[39]->nn_param.conv2d.pad[1] = 0;
    node[39]->nn_param.conv2d.pad[2] = 0;
    node[39]->nn_param.conv2d.pad[3] = 0;
    node[39]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[39]->nn_param.conv2d.group = 1;
    node[39]->nn_param.conv2d.dilation[0] = 1;
    node[39]->nn_param.conv2d.dilation[1] = 1;
    node[39]->nn_param.conv2d.multiplier = 0;
    node[39]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[39]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[39]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_34/conv/prelu/PRelu_output_0_74
      var       - node[40]
      name      - conv_34/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [20, 20, 231, 1]
      output    - [20, 20, 231, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[40], VSI_NN_OP_PRELU, 2, 1, 74);

    /*-----------------------------------------
      lid       - conv_34/conv_dw/conv/Conv_output_0_70
      var       - node[41]
      name      - conv_34/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [20, 20, 231, 1]
      filter    - [3, 3, 231, 1]
      output    - [10, 10, 231, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[41], VSI_NN_OP_CONV2D, 3, 1, 70);
    node[41]->nn_param.conv2d.ksize[0] = 3;
    node[41]->nn_param.conv2d.ksize[1] = 3;
    node[41]->nn_param.conv2d.weights = 231;
    node[41]->nn_param.conv2d.stride[0] = 2;
    node[41]->nn_param.conv2d.stride[1] = 2;
    node[41]->nn_param.conv2d.pad[0] = 1;
    node[41]->nn_param.conv2d.pad[1] = 1;
    node[41]->nn_param.conv2d.pad[2] = 1;
    node[41]->nn_param.conv2d.pad[3] = 1;
    node[41]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[41]->nn_param.conv2d.group = 231;
    node[41]->nn_param.conv2d.dilation[0] = 1;
    node[41]->nn_param.conv2d.dilation[1] = 1;
    node[41]->nn_param.conv2d.multiplier = 1;
    node[41]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[41]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[41]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_34/conv_dw/prelu/PRelu_output_0_65
      var       - node[42]
      name      - conv_34/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 231, 1]
      output    - [10, 10, 231, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[42], VSI_NN_OP_PRELU, 2, 1, 65);

    /*-----------------------------------------
      lid       - conv_34/project/conv/Conv_output_0_59
      var       - node[43]
      name      - conv_34/project/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 231, 1]
      filter    - [1, 1, 231, 128]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[43], VSI_NN_OP_CONV2D, 3, 1, 59);
    node[43]->nn_param.conv2d.ksize[0] = 1;
    node[43]->nn_param.conv2d.ksize[1] = 1;
    node[43]->nn_param.conv2d.weights = 128;
    node[43]->nn_param.conv2d.stride[0] = 1;
    node[43]->nn_param.conv2d.stride[1] = 1;
    node[43]->nn_param.conv2d.pad[0] = 0;
    node[43]->nn_param.conv2d.pad[1] = 0;
    node[43]->nn_param.conv2d.pad[2] = 0;
    node[43]->nn_param.conv2d.pad[3] = 0;
    node[43]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[43]->nn_param.conv2d.group = 1;
    node[43]->nn_param.conv2d.dilation[0] = 1;
    node[43]->nn_param.conv2d.dilation[1] = 1;
    node[43]->nn_param.conv2d.multiplier = 0;
    node[43]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[43]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[43]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/0/conv/conv/Conv_output_0_76
      var       - node[44]
      name      - conv_4/model/0/conv/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 128, 1]
      filter    - [1, 1, 128, 154]
      output    - [10, 10, 154, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[44], VSI_NN_OP_CONV2D, 3, 1, 76);
    node[44]->nn_param.conv2d.ksize[0] = 1;
    node[44]->nn_param.conv2d.ksize[1] = 1;
    node[44]->nn_param.conv2d.weights = 154;
    node[44]->nn_param.conv2d.stride[0] = 1;
    node[44]->nn_param.conv2d.stride[1] = 1;
    node[44]->nn_param.conv2d.pad[0] = 0;
    node[44]->nn_param.conv2d.pad[1] = 0;
    node[44]->nn_param.conv2d.pad[2] = 0;
    node[44]->nn_param.conv2d.pad[3] = 0;
    node[44]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[44]->nn_param.conv2d.group = 1;
    node[44]->nn_param.conv2d.dilation[0] = 1;
    node[44]->nn_param.conv2d.dilation[1] = 1;
    node[44]->nn_param.conv2d.multiplier = 0;
    node[44]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[44]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[44]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/0/conv/prelu/PRelu_output_0_75
      var       - node[45]
      name      - conv_4/model/0/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 154, 1]
      output    - [10, 10, 154, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[45], VSI_NN_OP_PRELU, 2, 1, 75);

    /*-----------------------------------------
      lid       - conv_4/model/0/conv_dw/conv/Conv_output_0_71
      var       - node[46]
      name      - conv_4/model/0/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 154, 1]
      filter    - [3, 3, 154, 1]
      output    - [10, 10, 154, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[46], VSI_NN_OP_CONV2D, 3, 1, 71);
    node[46]->nn_param.conv2d.ksize[0] = 3;
    node[46]->nn_param.conv2d.ksize[1] = 3;
    node[46]->nn_param.conv2d.weights = 154;
    node[46]->nn_param.conv2d.stride[0] = 1;
    node[46]->nn_param.conv2d.stride[1] = 1;
    node[46]->nn_param.conv2d.pad[0] = 1;
    node[46]->nn_param.conv2d.pad[1] = 1;
    node[46]->nn_param.conv2d.pad[2] = 1;
    node[46]->nn_param.conv2d.pad[3] = 1;
    node[46]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[46]->nn_param.conv2d.group = 154;
    node[46]->nn_param.conv2d.dilation[0] = 1;
    node[46]->nn_param.conv2d.dilation[1] = 1;
    node[46]->nn_param.conv2d.multiplier = 1;
    node[46]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[46]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[46]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/0/conv_dw/prelu/PRelu_output_0_66
      var       - node[47]
      name      - conv_4/model/0/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 154, 1]
      output    - [10, 10, 154, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[47], VSI_NN_OP_PRELU, 2, 1, 66);

    /*-----------------------------------------
      lid       - conv_4/model/0/project/conv/Conv_output_0_60
      var       - node[48]
      name      - conv_4/model/0/project/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 154, 1]
      filter    - [1, 1, 154, 128]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[48], VSI_NN_OP_CONV2D, 3, 1, 60);
    node[48]->nn_param.conv2d.ksize[0] = 1;
    node[48]->nn_param.conv2d.ksize[1] = 1;
    node[48]->nn_param.conv2d.weights = 128;
    node[48]->nn_param.conv2d.stride[0] = 1;
    node[48]->nn_param.conv2d.stride[1] = 1;
    node[48]->nn_param.conv2d.pad[0] = 0;
    node[48]->nn_param.conv2d.pad[1] = 0;
    node[48]->nn_param.conv2d.pad[2] = 0;
    node[48]->nn_param.conv2d.pad[3] = 0;
    node[48]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[48]->nn_param.conv2d.group = 1;
    node[48]->nn_param.conv2d.dilation[0] = 1;
    node[48]->nn_param.conv2d.dilation[1] = 1;
    node[48]->nn_param.conv2d.multiplier = 0;
    node[48]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[48]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[48]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/0/Add_output_0_53
      var       - node[49]
      name      - conv_4/model/0/Add_output_0
      operation - add
      input     - [10, 10, 128, 1]
                  [10, 10, 128, 1]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[49], VSI_NN_OP_ADD, 2, 1, 53);

    /*-----------------------------------------
      lid       - conv_4/model/1/conv/conv/Conv_output_0_73
      var       - node[50]
      name      - conv_4/model/1/conv/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 128, 1]
      filter    - [1, 1, 128, 52]
      output    - [10, 10, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[50], VSI_NN_OP_CONV2D, 3, 1, 73);
    node[50]->nn_param.conv2d.ksize[0] = 1;
    node[50]->nn_param.conv2d.ksize[1] = 1;
    node[50]->nn_param.conv2d.weights = 52;
    node[50]->nn_param.conv2d.stride[0] = 1;
    node[50]->nn_param.conv2d.stride[1] = 1;
    node[50]->nn_param.conv2d.pad[0] = 0;
    node[50]->nn_param.conv2d.pad[1] = 0;
    node[50]->nn_param.conv2d.pad[2] = 0;
    node[50]->nn_param.conv2d.pad[3] = 0;
    node[50]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[50]->nn_param.conv2d.group = 1;
    node[50]->nn_param.conv2d.dilation[0] = 1;
    node[50]->nn_param.conv2d.dilation[1] = 1;
    node[50]->nn_param.conv2d.multiplier = 0;
    node[50]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[50]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[50]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/1/conv/prelu/PRelu_output_0_72
      var       - node[51]
      name      - conv_4/model/1/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 52, 1]
      output    - [10, 10, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[51], VSI_NN_OP_PRELU, 2, 1, 72);

    /*-----------------------------------------
      lid       - conv_4/model/1/conv_dw/conv/Conv_output_0_67
      var       - node[52]
      name      - conv_4/model/1/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 52, 1]
      filter    - [3, 3, 52, 1]
      output    - [10, 10, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[52], VSI_NN_OP_CONV2D, 3, 1, 67);
    node[52]->nn_param.conv2d.ksize[0] = 3;
    node[52]->nn_param.conv2d.ksize[1] = 3;
    node[52]->nn_param.conv2d.weights = 52;
    node[52]->nn_param.conv2d.stride[0] = 1;
    node[52]->nn_param.conv2d.stride[1] = 1;
    node[52]->nn_param.conv2d.pad[0] = 1;
    node[52]->nn_param.conv2d.pad[1] = 1;
    node[52]->nn_param.conv2d.pad[2] = 1;
    node[52]->nn_param.conv2d.pad[3] = 1;
    node[52]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[52]->nn_param.conv2d.group = 52;
    node[52]->nn_param.conv2d.dilation[0] = 1;
    node[52]->nn_param.conv2d.dilation[1] = 1;
    node[52]->nn_param.conv2d.multiplier = 1;
    node[52]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[52]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[52]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/1/conv_dw/prelu/PRelu_output_0_61
      var       - node[53]
      name      - conv_4/model/1/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 52, 1]
      output    - [10, 10, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[53], VSI_NN_OP_PRELU, 2, 1, 61);

    /*-----------------------------------------
      lid       - conv_4/model/1/project/conv/Conv_output_0_54
      var       - node[54]
      name      - conv_4/model/1/project/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 52, 1]
      filter    - [1, 1, 52, 128]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[54], VSI_NN_OP_CONV2D, 3, 1, 54);
    node[54]->nn_param.conv2d.ksize[0] = 1;
    node[54]->nn_param.conv2d.ksize[1] = 1;
    node[54]->nn_param.conv2d.weights = 128;
    node[54]->nn_param.conv2d.stride[0] = 1;
    node[54]->nn_param.conv2d.stride[1] = 1;
    node[54]->nn_param.conv2d.pad[0] = 0;
    node[54]->nn_param.conv2d.pad[1] = 0;
    node[54]->nn_param.conv2d.pad[2] = 0;
    node[54]->nn_param.conv2d.pad[3] = 0;
    node[54]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[54]->nn_param.conv2d.group = 1;
    node[54]->nn_param.conv2d.dilation[0] = 1;
    node[54]->nn_param.conv2d.dilation[1] = 1;
    node[54]->nn_param.conv2d.multiplier = 0;
    node[54]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[54]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[54]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/1/Add_output_0_47
      var       - node[55]
      name      - conv_4/model/1/Add_output_0
      operation - add
      input     - [10, 10, 128, 1]
                  [10, 10, 128, 1]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[55], VSI_NN_OP_ADD, 2, 1, 47);

    /*-----------------------------------------
      lid       - conv_4/model/2/conv/conv/Conv_output_0_69
      var       - node[56]
      name      - conv_4/model/2/conv/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 128, 1]
      filter    - [1, 1, 128, 26]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[56], VSI_NN_OP_CONV2D, 3, 1, 69);
    node[56]->nn_param.conv2d.ksize[0] = 1;
    node[56]->nn_param.conv2d.ksize[1] = 1;
    node[56]->nn_param.conv2d.weights = 26;
    node[56]->nn_param.conv2d.stride[0] = 1;
    node[56]->nn_param.conv2d.stride[1] = 1;
    node[56]->nn_param.conv2d.pad[0] = 0;
    node[56]->nn_param.conv2d.pad[1] = 0;
    node[56]->nn_param.conv2d.pad[2] = 0;
    node[56]->nn_param.conv2d.pad[3] = 0;
    node[56]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[56]->nn_param.conv2d.group = 1;
    node[56]->nn_param.conv2d.dilation[0] = 1;
    node[56]->nn_param.conv2d.dilation[1] = 1;
    node[56]->nn_param.conv2d.multiplier = 0;
    node[56]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[56]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[56]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/2/conv/prelu/PRelu_output_0_68
      var       - node[57]
      name      - conv_4/model/2/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[57], VSI_NN_OP_PRELU, 2, 1, 68);

    /*-----------------------------------------
      lid       - conv_4/model/2/conv_dw/conv/Conv_output_0_62
      var       - node[58]
      name      - conv_4/model/2/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 26, 1]
      filter    - [3, 3, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[58], VSI_NN_OP_CONV2D, 3, 1, 62);
    node[58]->nn_param.conv2d.ksize[0] = 3;
    node[58]->nn_param.conv2d.ksize[1] = 3;
    node[58]->nn_param.conv2d.weights = 26;
    node[58]->nn_param.conv2d.stride[0] = 1;
    node[58]->nn_param.conv2d.stride[1] = 1;
    node[58]->nn_param.conv2d.pad[0] = 1;
    node[58]->nn_param.conv2d.pad[1] = 1;
    node[58]->nn_param.conv2d.pad[2] = 1;
    node[58]->nn_param.conv2d.pad[3] = 1;
    node[58]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[58]->nn_param.conv2d.group = 26;
    node[58]->nn_param.conv2d.dilation[0] = 1;
    node[58]->nn_param.conv2d.dilation[1] = 1;
    node[58]->nn_param.conv2d.multiplier = 1;
    node[58]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[58]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[58]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/2/conv_dw/prelu/PRelu_output_0_55
      var       - node[59]
      name      - conv_4/model/2/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[59], VSI_NN_OP_PRELU, 2, 1, 55);

    /*-----------------------------------------
      lid       - conv_4/model/2/project/conv/Conv_output_0_48
      var       - node[60]
      name      - conv_4/model/2/project/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 26, 1]
      filter    - [1, 1, 26, 128]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[60], VSI_NN_OP_CONV2D, 3, 1, 48);
    node[60]->nn_param.conv2d.ksize[0] = 1;
    node[60]->nn_param.conv2d.ksize[1] = 1;
    node[60]->nn_param.conv2d.weights = 128;
    node[60]->nn_param.conv2d.stride[0] = 1;
    node[60]->nn_param.conv2d.stride[1] = 1;
    node[60]->nn_param.conv2d.pad[0] = 0;
    node[60]->nn_param.conv2d.pad[1] = 0;
    node[60]->nn_param.conv2d.pad[2] = 0;
    node[60]->nn_param.conv2d.pad[3] = 0;
    node[60]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[60]->nn_param.conv2d.group = 1;
    node[60]->nn_param.conv2d.dilation[0] = 1;
    node[60]->nn_param.conv2d.dilation[1] = 1;
    node[60]->nn_param.conv2d.multiplier = 0;
    node[60]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[60]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[60]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/2/Add_output_0_42
      var       - node[61]
      name      - conv_4/model/2/Add_output_0
      operation - add
      input     - [10, 10, 128, 1]
                  [10, 10, 128, 1]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[61], VSI_NN_OP_ADD, 2, 1, 42);

    /*-----------------------------------------
      lid       - conv_4/model/3/conv/conv/Conv_output_0_64
      var       - node[62]
      name      - conv_4/model/3/conv/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 128, 1]
      filter    - [1, 1, 128, 52]
      output    - [10, 10, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[62], VSI_NN_OP_CONV2D, 3, 1, 64);
    node[62]->nn_param.conv2d.ksize[0] = 1;
    node[62]->nn_param.conv2d.ksize[1] = 1;
    node[62]->nn_param.conv2d.weights = 52;
    node[62]->nn_param.conv2d.stride[0] = 1;
    node[62]->nn_param.conv2d.stride[1] = 1;
    node[62]->nn_param.conv2d.pad[0] = 0;
    node[62]->nn_param.conv2d.pad[1] = 0;
    node[62]->nn_param.conv2d.pad[2] = 0;
    node[62]->nn_param.conv2d.pad[3] = 0;
    node[62]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[62]->nn_param.conv2d.group = 1;
    node[62]->nn_param.conv2d.dilation[0] = 1;
    node[62]->nn_param.conv2d.dilation[1] = 1;
    node[62]->nn_param.conv2d.multiplier = 0;
    node[62]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[62]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[62]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/3/conv/prelu/PRelu_output_0_63
      var       - node[63]
      name      - conv_4/model/3/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 52, 1]
      output    - [10, 10, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[63], VSI_NN_OP_PRELU, 2, 1, 63);

    /*-----------------------------------------
      lid       - conv_4/model/3/conv_dw/conv/Conv_output_0_56
      var       - node[64]
      name      - conv_4/model/3/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 52, 1]
      filter    - [3, 3, 52, 1]
      output    - [10, 10, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[64], VSI_NN_OP_CONV2D, 3, 1, 56);
    node[64]->nn_param.conv2d.ksize[0] = 3;
    node[64]->nn_param.conv2d.ksize[1] = 3;
    node[64]->nn_param.conv2d.weights = 52;
    node[64]->nn_param.conv2d.stride[0] = 1;
    node[64]->nn_param.conv2d.stride[1] = 1;
    node[64]->nn_param.conv2d.pad[0] = 1;
    node[64]->nn_param.conv2d.pad[1] = 1;
    node[64]->nn_param.conv2d.pad[2] = 1;
    node[64]->nn_param.conv2d.pad[3] = 1;
    node[64]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[64]->nn_param.conv2d.group = 52;
    node[64]->nn_param.conv2d.dilation[0] = 1;
    node[64]->nn_param.conv2d.dilation[1] = 1;
    node[64]->nn_param.conv2d.multiplier = 1;
    node[64]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[64]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[64]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/3/conv_dw/prelu/PRelu_output_0_49
      var       - node[65]
      name      - conv_4/model/3/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 52, 1]
      output    - [10, 10, 52, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[65], VSI_NN_OP_PRELU, 2, 1, 49);

    /*-----------------------------------------
      lid       - conv_4/model/3/project/conv/Conv_output_0_43
      var       - node[66]
      name      - conv_4/model/3/project/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 52, 1]
      filter    - [1, 1, 52, 128]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[66], VSI_NN_OP_CONV2D, 3, 1, 43);
    node[66]->nn_param.conv2d.ksize[0] = 1;
    node[66]->nn_param.conv2d.ksize[1] = 1;
    node[66]->nn_param.conv2d.weights = 128;
    node[66]->nn_param.conv2d.stride[0] = 1;
    node[66]->nn_param.conv2d.stride[1] = 1;
    node[66]->nn_param.conv2d.pad[0] = 0;
    node[66]->nn_param.conv2d.pad[1] = 0;
    node[66]->nn_param.conv2d.pad[2] = 0;
    node[66]->nn_param.conv2d.pad[3] = 0;
    node[66]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[66]->nn_param.conv2d.group = 1;
    node[66]->nn_param.conv2d.dilation[0] = 1;
    node[66]->nn_param.conv2d.dilation[1] = 1;
    node[66]->nn_param.conv2d.multiplier = 0;
    node[66]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[66]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[66]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/3/Add_output_0_38
      var       - node[67]
      name      - conv_4/model/3/Add_output_0
      operation - add
      input     - [10, 10, 128, 1]
                  [10, 10, 128, 1]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[67], VSI_NN_OP_ADD, 2, 1, 38);

    /*-----------------------------------------
      lid       - conv_4/model/4/conv/conv/Conv_output_0_58
      var       - node[68]
      name      - conv_4/model/4/conv/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 128, 1]
      filter    - [1, 1, 128, 26]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[68], VSI_NN_OP_CONV2D, 3, 1, 58);
    node[68]->nn_param.conv2d.ksize[0] = 1;
    node[68]->nn_param.conv2d.ksize[1] = 1;
    node[68]->nn_param.conv2d.weights = 26;
    node[68]->nn_param.conv2d.stride[0] = 1;
    node[68]->nn_param.conv2d.stride[1] = 1;
    node[68]->nn_param.conv2d.pad[0] = 0;
    node[68]->nn_param.conv2d.pad[1] = 0;
    node[68]->nn_param.conv2d.pad[2] = 0;
    node[68]->nn_param.conv2d.pad[3] = 0;
    node[68]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[68]->nn_param.conv2d.group = 1;
    node[68]->nn_param.conv2d.dilation[0] = 1;
    node[68]->nn_param.conv2d.dilation[1] = 1;
    node[68]->nn_param.conv2d.multiplier = 0;
    node[68]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[68]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[68]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/4/conv/prelu/PRelu_output_0_57
      var       - node[69]
      name      - conv_4/model/4/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[69], VSI_NN_OP_PRELU, 2, 1, 57);

    /*-----------------------------------------
      lid       - conv_4/model/4/conv_dw/conv/Conv_output_0_50
      var       - node[70]
      name      - conv_4/model/4/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 26, 1]
      filter    - [3, 3, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[70], VSI_NN_OP_CONV2D, 3, 1, 50);
    node[70]->nn_param.conv2d.ksize[0] = 3;
    node[70]->nn_param.conv2d.ksize[1] = 3;
    node[70]->nn_param.conv2d.weights = 26;
    node[70]->nn_param.conv2d.stride[0] = 1;
    node[70]->nn_param.conv2d.stride[1] = 1;
    node[70]->nn_param.conv2d.pad[0] = 1;
    node[70]->nn_param.conv2d.pad[1] = 1;
    node[70]->nn_param.conv2d.pad[2] = 1;
    node[70]->nn_param.conv2d.pad[3] = 1;
    node[70]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[70]->nn_param.conv2d.group = 26;
    node[70]->nn_param.conv2d.dilation[0] = 1;
    node[70]->nn_param.conv2d.dilation[1] = 1;
    node[70]->nn_param.conv2d.multiplier = 1;
    node[70]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[70]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[70]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/4/conv_dw/prelu/PRelu_output_0_44
      var       - node[71]
      name      - conv_4/model/4/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[71], VSI_NN_OP_PRELU, 2, 1, 44);

    /*-----------------------------------------
      lid       - conv_4/model/4/project/conv/Conv_output_0_39
      var       - node[72]
      name      - conv_4/model/4/project/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 26, 1]
      filter    - [1, 1, 26, 128]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[72], VSI_NN_OP_CONV2D, 3, 1, 39);
    node[72]->nn_param.conv2d.ksize[0] = 1;
    node[72]->nn_param.conv2d.ksize[1] = 1;
    node[72]->nn_param.conv2d.weights = 128;
    node[72]->nn_param.conv2d.stride[0] = 1;
    node[72]->nn_param.conv2d.stride[1] = 1;
    node[72]->nn_param.conv2d.pad[0] = 0;
    node[72]->nn_param.conv2d.pad[1] = 0;
    node[72]->nn_param.conv2d.pad[2] = 0;
    node[72]->nn_param.conv2d.pad[3] = 0;
    node[72]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[72]->nn_param.conv2d.group = 1;
    node[72]->nn_param.conv2d.dilation[0] = 1;
    node[72]->nn_param.conv2d.dilation[1] = 1;
    node[72]->nn_param.conv2d.multiplier = 0;
    node[72]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[72]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[72]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/4/Add_output_0_35
      var       - node[73]
      name      - conv_4/model/4/Add_output_0
      operation - add
      input     - [10, 10, 128, 1]
                  [10, 10, 128, 1]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[73], VSI_NN_OP_ADD, 2, 1, 35);

    /*-----------------------------------------
      lid       - conv_4/model/5/conv/conv/Conv_output_0_52
      var       - node[74]
      name      - conv_4/model/5/conv/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 128, 1]
      filter    - [1, 1, 128, 26]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[74], VSI_NN_OP_CONV2D, 3, 1, 52);
    node[74]->nn_param.conv2d.ksize[0] = 1;
    node[74]->nn_param.conv2d.ksize[1] = 1;
    node[74]->nn_param.conv2d.weights = 26;
    node[74]->nn_param.conv2d.stride[0] = 1;
    node[74]->nn_param.conv2d.stride[1] = 1;
    node[74]->nn_param.conv2d.pad[0] = 0;
    node[74]->nn_param.conv2d.pad[1] = 0;
    node[74]->nn_param.conv2d.pad[2] = 0;
    node[74]->nn_param.conv2d.pad[3] = 0;
    node[74]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[74]->nn_param.conv2d.group = 1;
    node[74]->nn_param.conv2d.dilation[0] = 1;
    node[74]->nn_param.conv2d.dilation[1] = 1;
    node[74]->nn_param.conv2d.multiplier = 0;
    node[74]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[74]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[74]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/5/conv/prelu/PRelu_output_0_51
      var       - node[75]
      name      - conv_4/model/5/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[75], VSI_NN_OP_PRELU, 2, 1, 51);

    /*-----------------------------------------
      lid       - conv_4/model/5/conv_dw/conv/Conv_output_0_45
      var       - node[76]
      name      - conv_4/model/5/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 26, 1]
      filter    - [3, 3, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[76], VSI_NN_OP_CONV2D, 3, 1, 45);
    node[76]->nn_param.conv2d.ksize[0] = 3;
    node[76]->nn_param.conv2d.ksize[1] = 3;
    node[76]->nn_param.conv2d.weights = 26;
    node[76]->nn_param.conv2d.stride[0] = 1;
    node[76]->nn_param.conv2d.stride[1] = 1;
    node[76]->nn_param.conv2d.pad[0] = 1;
    node[76]->nn_param.conv2d.pad[1] = 1;
    node[76]->nn_param.conv2d.pad[2] = 1;
    node[76]->nn_param.conv2d.pad[3] = 1;
    node[76]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[76]->nn_param.conv2d.group = 26;
    node[76]->nn_param.conv2d.dilation[0] = 1;
    node[76]->nn_param.conv2d.dilation[1] = 1;
    node[76]->nn_param.conv2d.multiplier = 1;
    node[76]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[76]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[76]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/5/conv_dw/prelu/PRelu_output_0_40
      var       - node[77]
      name      - conv_4/model/5/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 26, 1]
      output    - [10, 10, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[77], VSI_NN_OP_PRELU, 2, 1, 40);

    /*-----------------------------------------
      lid       - conv_4/model/5/project/conv/Conv_output_0_36
      var       - node[78]
      name      - conv_4/model/5/project/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 26, 1]
      filter    - [1, 1, 26, 128]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[78], VSI_NN_OP_CONV2D, 3, 1, 36);
    node[78]->nn_param.conv2d.ksize[0] = 1;
    node[78]->nn_param.conv2d.ksize[1] = 1;
    node[78]->nn_param.conv2d.weights = 128;
    node[78]->nn_param.conv2d.stride[0] = 1;
    node[78]->nn_param.conv2d.stride[1] = 1;
    node[78]->nn_param.conv2d.pad[0] = 0;
    node[78]->nn_param.conv2d.pad[1] = 0;
    node[78]->nn_param.conv2d.pad[2] = 0;
    node[78]->nn_param.conv2d.pad[3] = 0;
    node[78]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[78]->nn_param.conv2d.group = 1;
    node[78]->nn_param.conv2d.dilation[0] = 1;
    node[78]->nn_param.conv2d.dilation[1] = 1;
    node[78]->nn_param.conv2d.multiplier = 0;
    node[78]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[78]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[78]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/5/se_module/avg_pool/GlobalAveragePool_output_0_46
      var       - node[79]
      name      - conv_4/model/5/se_module/avg_pool/GlobalAveragePool_output_0
      operation - pooling
      input     - [10, 10, 128, 1]
      output    - [1, 1, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[79], VSI_NN_OP_POOL, 1, 1, 46);
    node[79]->nn_param.pool.ksize[0] = 10;
    node[79]->nn_param.pool.ksize[1] = 10;
    node[79]->nn_param.pool.stride[0] = 1;
    node[79]->nn_param.pool.stride[1] = 1;
    node[79]->nn_param.pool.pad[0] = 0;
    node[79]->nn_param.pool.pad[1] = 0;
    node[79]->nn_param.pool.pad[2] = 0;
    node[79]->nn_param.pool.pad[3] = 0;
    node[79]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[79]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[79]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/5/se_module/fc1/Conv_output_0_41
      var       - node[80]
      name      - conv_4/model/5/se_module/fc1/Conv_output_0
      operation - convolution
      input     - [1, 1, 128, 1]
      filter    - [1, 1, 128, 32]
      output    - [1, 1, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[80], VSI_NN_OP_CONV2D, 3, 1, 41);
    node[80]->nn_param.conv2d.ksize[0] = 1;
    node[80]->nn_param.conv2d.ksize[1] = 1;
    node[80]->nn_param.conv2d.weights = 32;
    node[80]->nn_param.conv2d.stride[0] = 1;
    node[80]->nn_param.conv2d.stride[1] = 1;
    node[80]->nn_param.conv2d.pad[0] = 0;
    node[80]->nn_param.conv2d.pad[1] = 0;
    node[80]->nn_param.conv2d.pad[2] = 0;
    node[80]->nn_param.conv2d.pad[3] = 0;
    node[80]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[80]->nn_param.conv2d.group = 1;
    node[80]->nn_param.conv2d.dilation[0] = 1;
    node[80]->nn_param.conv2d.dilation[1] = 1;
    node[80]->nn_param.conv2d.multiplier = 0;
    node[80]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[80]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[80]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/5/se_module/relu/Relu_output_0_37
      var       - node[81]
      name      - conv_4/model/5/se_module/relu/Relu_output_0
      operation - relu
      input     - [1, 1, 32, 1]
      output    - [1, 1, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[81], VSI_NN_OP_RELU, 1, 1, 37);

    /*-----------------------------------------
      lid       - conv_4/model/5/se_module/fc2/Conv_output_0_34
      var       - node[82]
      name      - conv_4/model/5/se_module/fc2/Conv_output_0
      operation - convolution
      input     - [1, 1, 32, 1]
      filter    - [1, 1, 32, 128]
      output    - [1, 1, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[82], VSI_NN_OP_CONV2D, 3, 1, 34);
    node[82]->nn_param.conv2d.ksize[0] = 1;
    node[82]->nn_param.conv2d.ksize[1] = 1;
    node[82]->nn_param.conv2d.weights = 128;
    node[82]->nn_param.conv2d.stride[0] = 1;
    node[82]->nn_param.conv2d.stride[1] = 1;
    node[82]->nn_param.conv2d.pad[0] = 0;
    node[82]->nn_param.conv2d.pad[1] = 0;
    node[82]->nn_param.conv2d.pad[2] = 0;
    node[82]->nn_param.conv2d.pad[3] = 0;
    node[82]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[82]->nn_param.conv2d.group = 1;
    node[82]->nn_param.conv2d.dilation[0] = 1;
    node[82]->nn_param.conv2d.dilation[1] = 1;
    node[82]->nn_param.conv2d.multiplier = 0;
    node[82]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[82]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[82]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_4/model/5/se_module/sigmoid/Sigmoid_output_0_33
      var       - node[83]
      name      - conv_4/model/5/se_module/sigmoid/Sigmoid_output_0
      operation - sigmoid
      input     - [1, 1, 128, 1]
      output    - [1, 1, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[83], VSI_NN_OP_SIGMOID, 1, 1, 33);

    /*-----------------------------------------
      lid       - conv_4/model/5/se_module/Mul_output_0_32
      var       - node[84]
      name      - conv_4/model/5/se_module/Mul_output_0
      operation - multiply
      input     - [10, 10, 128, 1]
                  [1, 1, 128, 1]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[84], VSI_NN_OP_MULTIPLY, 2, 1, 32);
    node[84]->nn_param.multiply.scale = 1;
    node[84]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[84]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - conv_4/model/5/Add_output_0_31
      var       - node[85]
      name      - conv_4/model/5/Add_output_0
      operation - add
      input     - [10, 10, 128, 1]
                  [10, 10, 128, 1]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[85], VSI_NN_OP_ADD, 2, 1, 31);

    /*-----------------------------------------
      lid       - conv_45/conv/conv/Conv_output_0_27
      var       - node[86]
      name      - conv_45/conv/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 128, 1]
      filter    - [1, 1, 128, 308]
      output    - [10, 10, 308, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[86], VSI_NN_OP_CONV2D, 3, 1, 27);
    node[86]->nn_param.conv2d.ksize[0] = 1;
    node[86]->nn_param.conv2d.ksize[1] = 1;
    node[86]->nn_param.conv2d.weights = 308;
    node[86]->nn_param.conv2d.stride[0] = 1;
    node[86]->nn_param.conv2d.stride[1] = 1;
    node[86]->nn_param.conv2d.pad[0] = 0;
    node[86]->nn_param.conv2d.pad[1] = 0;
    node[86]->nn_param.conv2d.pad[2] = 0;
    node[86]->nn_param.conv2d.pad[3] = 0;
    node[86]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[86]->nn_param.conv2d.group = 1;
    node[86]->nn_param.conv2d.dilation[0] = 1;
    node[86]->nn_param.conv2d.dilation[1] = 1;
    node[86]->nn_param.conv2d.multiplier = 0;
    node[86]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[86]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[86]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_45/conv/prelu/PRelu_output_0_23
      var       - node[87]
      name      - conv_45/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [10, 10, 308, 1]
      output    - [10, 10, 308, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[87], VSI_NN_OP_PRELU, 2, 1, 23);

    /*-----------------------------------------
      lid       - conv_45/conv_dw/conv/Conv_output_0_19
      var       - node[88]
      name      - conv_45/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [10, 10, 308, 1]
      filter    - [3, 3, 308, 1]
      output    - [5, 5, 308, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[88], VSI_NN_OP_CONV2D, 3, 1, 19);
    node[88]->nn_param.conv2d.ksize[0] = 3;
    node[88]->nn_param.conv2d.ksize[1] = 3;
    node[88]->nn_param.conv2d.weights = 308;
    node[88]->nn_param.conv2d.stride[0] = 2;
    node[88]->nn_param.conv2d.stride[1] = 2;
    node[88]->nn_param.conv2d.pad[0] = 1;
    node[88]->nn_param.conv2d.pad[1] = 1;
    node[88]->nn_param.conv2d.pad[2] = 1;
    node[88]->nn_param.conv2d.pad[3] = 1;
    node[88]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[88]->nn_param.conv2d.group = 308;
    node[88]->nn_param.conv2d.dilation[0] = 1;
    node[88]->nn_param.conv2d.dilation[1] = 1;
    node[88]->nn_param.conv2d.multiplier = 1;
    node[88]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[88]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[88]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_45/conv_dw/prelu/PRelu_output_0_15
      var       - node[89]
      name      - conv_45/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [5, 5, 308, 1]
      output    - [5, 5, 308, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[89], VSI_NN_OP_PRELU, 2, 1, 15);

    /*-----------------------------------------
      lid       - conv_45/project/conv/Conv_output_0_11
      var       - node[90]
      name      - conv_45/project/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 308, 1]
      filter    - [1, 1, 308, 128]
      output    - [5, 5, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[90], VSI_NN_OP_CONV2D, 3, 1, 11);
    node[90]->nn_param.conv2d.ksize[0] = 1;
    node[90]->nn_param.conv2d.ksize[1] = 1;
    node[90]->nn_param.conv2d.weights = 128;
    node[90]->nn_param.conv2d.stride[0] = 1;
    node[90]->nn_param.conv2d.stride[1] = 1;
    node[90]->nn_param.conv2d.pad[0] = 0;
    node[90]->nn_param.conv2d.pad[1] = 0;
    node[90]->nn_param.conv2d.pad[2] = 0;
    node[90]->nn_param.conv2d.pad[3] = 0;
    node[90]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[90]->nn_param.conv2d.group = 1;
    node[90]->nn_param.conv2d.dilation[0] = 1;
    node[90]->nn_param.conv2d.dilation[1] = 1;
    node[90]->nn_param.conv2d.multiplier = 0;
    node[90]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[90]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[90]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/0/conv/conv/Conv_output_0_28
      var       - node[91]
      name      - conv_5/model/0/conv/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 128, 1]
      filter    - [1, 1, 128, 26]
      output    - [5, 5, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[91], VSI_NN_OP_CONV2D, 3, 1, 28);
    node[91]->nn_param.conv2d.ksize[0] = 1;
    node[91]->nn_param.conv2d.ksize[1] = 1;
    node[91]->nn_param.conv2d.weights = 26;
    node[91]->nn_param.conv2d.stride[0] = 1;
    node[91]->nn_param.conv2d.stride[1] = 1;
    node[91]->nn_param.conv2d.pad[0] = 0;
    node[91]->nn_param.conv2d.pad[1] = 0;
    node[91]->nn_param.conv2d.pad[2] = 0;
    node[91]->nn_param.conv2d.pad[3] = 0;
    node[91]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[91]->nn_param.conv2d.group = 1;
    node[91]->nn_param.conv2d.dilation[0] = 1;
    node[91]->nn_param.conv2d.dilation[1] = 1;
    node[91]->nn_param.conv2d.multiplier = 0;
    node[91]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[91]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[91]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/0/conv/prelu/PRelu_output_0_24
      var       - node[92]
      name      - conv_5/model/0/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [5, 5, 26, 1]
      output    - [5, 5, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[92], VSI_NN_OP_PRELU, 2, 1, 24);

    /*-----------------------------------------
      lid       - conv_5/model/0/conv_dw/conv/Conv_output_0_20
      var       - node[93]
      name      - conv_5/model/0/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 26, 1]
      filter    - [3, 3, 26, 1]
      output    - [5, 5, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[93], VSI_NN_OP_CONV2D, 3, 1, 20);
    node[93]->nn_param.conv2d.ksize[0] = 3;
    node[93]->nn_param.conv2d.ksize[1] = 3;
    node[93]->nn_param.conv2d.weights = 26;
    node[93]->nn_param.conv2d.stride[0] = 1;
    node[93]->nn_param.conv2d.stride[1] = 1;
    node[93]->nn_param.conv2d.pad[0] = 1;
    node[93]->nn_param.conv2d.pad[1] = 1;
    node[93]->nn_param.conv2d.pad[2] = 1;
    node[93]->nn_param.conv2d.pad[3] = 1;
    node[93]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[93]->nn_param.conv2d.group = 26;
    node[93]->nn_param.conv2d.dilation[0] = 1;
    node[93]->nn_param.conv2d.dilation[1] = 1;
    node[93]->nn_param.conv2d.multiplier = 1;
    node[93]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[93]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[93]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/0/conv_dw/prelu/PRelu_output_0_16
      var       - node[94]
      name      - conv_5/model/0/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [5, 5, 26, 1]
      output    - [5, 5, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[94], VSI_NN_OP_PRELU, 2, 1, 16);

    /*-----------------------------------------
      lid       - conv_5/model/0/project/conv/Conv_output_0_12
      var       - node[95]
      name      - conv_5/model/0/project/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 26, 1]
      filter    - [1, 1, 26, 128]
      output    - [5, 5, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[95], VSI_NN_OP_CONV2D, 3, 1, 12);
    node[95]->nn_param.conv2d.ksize[0] = 1;
    node[95]->nn_param.conv2d.ksize[1] = 1;
    node[95]->nn_param.conv2d.weights = 128;
    node[95]->nn_param.conv2d.stride[0] = 1;
    node[95]->nn_param.conv2d.stride[1] = 1;
    node[95]->nn_param.conv2d.pad[0] = 0;
    node[95]->nn_param.conv2d.pad[1] = 0;
    node[95]->nn_param.conv2d.pad[2] = 0;
    node[95]->nn_param.conv2d.pad[3] = 0;
    node[95]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[95]->nn_param.conv2d.group = 1;
    node[95]->nn_param.conv2d.dilation[0] = 1;
    node[95]->nn_param.conv2d.dilation[1] = 1;
    node[95]->nn_param.conv2d.multiplier = 0;
    node[95]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[95]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[95]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/0/Add_output_0_9
      var       - node[96]
      name      - conv_5/model/0/Add_output_0
      operation - add
      input     - [5, 5, 128, 1]
                  [5, 5, 128, 1]
      output    - [5, 5, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[96], VSI_NN_OP_ADD, 2, 1, 9);

    /*-----------------------------------------
      lid       - conv_5/model/1/conv/conv/Conv_output_0_29
      var       - node[97]
      name      - conv_5/model/1/conv/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 128, 1]
      filter    - [1, 1, 128, 26]
      output    - [5, 5, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[97], VSI_NN_OP_CONV2D, 3, 1, 29);
    node[97]->nn_param.conv2d.ksize[0] = 1;
    node[97]->nn_param.conv2d.ksize[1] = 1;
    node[97]->nn_param.conv2d.weights = 26;
    node[97]->nn_param.conv2d.stride[0] = 1;
    node[97]->nn_param.conv2d.stride[1] = 1;
    node[97]->nn_param.conv2d.pad[0] = 0;
    node[97]->nn_param.conv2d.pad[1] = 0;
    node[97]->nn_param.conv2d.pad[2] = 0;
    node[97]->nn_param.conv2d.pad[3] = 0;
    node[97]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[97]->nn_param.conv2d.group = 1;
    node[97]->nn_param.conv2d.dilation[0] = 1;
    node[97]->nn_param.conv2d.dilation[1] = 1;
    node[97]->nn_param.conv2d.multiplier = 0;
    node[97]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[97]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[97]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/1/conv/prelu/PRelu_output_0_25
      var       - node[98]
      name      - conv_5/model/1/conv/prelu/PRelu_output_0
      operation - prelu
      input     - [5, 5, 26, 1]
      output    - [5, 5, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[98], VSI_NN_OP_PRELU, 2, 1, 25);

    /*-----------------------------------------
      lid       - conv_5/model/1/conv_dw/conv/Conv_output_0_21
      var       - node[99]
      name      - conv_5/model/1/conv_dw/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 26, 1]
      filter    - [3, 3, 26, 1]
      output    - [5, 5, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[99], VSI_NN_OP_CONV2D, 3, 1, 21);
    node[99]->nn_param.conv2d.ksize[0] = 3;
    node[99]->nn_param.conv2d.ksize[1] = 3;
    node[99]->nn_param.conv2d.weights = 26;
    node[99]->nn_param.conv2d.stride[0] = 1;
    node[99]->nn_param.conv2d.stride[1] = 1;
    node[99]->nn_param.conv2d.pad[0] = 1;
    node[99]->nn_param.conv2d.pad[1] = 1;
    node[99]->nn_param.conv2d.pad[2] = 1;
    node[99]->nn_param.conv2d.pad[3] = 1;
    node[99]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[99]->nn_param.conv2d.group = 26;
    node[99]->nn_param.conv2d.dilation[0] = 1;
    node[99]->nn_param.conv2d.dilation[1] = 1;
    node[99]->nn_param.conv2d.multiplier = 1;
    node[99]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[99]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[99]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/1/conv_dw/prelu/PRelu_output_0_17
      var       - node[100]
      name      - conv_5/model/1/conv_dw/prelu/PRelu_output_0
      operation - prelu
      input     - [5, 5, 26, 1]
      output    - [5, 5, 26, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[100], VSI_NN_OP_PRELU, 2, 1, 17);

    /*-----------------------------------------
      lid       - conv_5/model/1/project/conv/Conv_output_0_13
      var       - node[101]
      name      - conv_5/model/1/project/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 26, 1]
      filter    - [1, 1, 26, 128]
      output    - [5, 5, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[101], VSI_NN_OP_CONV2D, 3, 1, 13);
    node[101]->nn_param.conv2d.ksize[0] = 1;
    node[101]->nn_param.conv2d.ksize[1] = 1;
    node[101]->nn_param.conv2d.weights = 128;
    node[101]->nn_param.conv2d.stride[0] = 1;
    node[101]->nn_param.conv2d.stride[1] = 1;
    node[101]->nn_param.conv2d.pad[0] = 0;
    node[101]->nn_param.conv2d.pad[1] = 0;
    node[101]->nn_param.conv2d.pad[2] = 0;
    node[101]->nn_param.conv2d.pad[3] = 0;
    node[101]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[101]->nn_param.conv2d.group = 1;
    node[101]->nn_param.conv2d.dilation[0] = 1;
    node[101]->nn_param.conv2d.dilation[1] = 1;
    node[101]->nn_param.conv2d.multiplier = 0;
    node[101]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[101]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[101]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/1/se_module/avg_pool/GlobalAveragePool_output_0_30
      var       - node[102]
      name      - conv_5/model/1/se_module/avg_pool/GlobalAveragePool_output_0
      operation - pooling
      input     - [5, 5, 128, 1]
      output    - [1, 1, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[102], VSI_NN_OP_POOL, 1, 1, 30);
    node[102]->nn_param.pool.ksize[0] = 5;
    node[102]->nn_param.pool.ksize[1] = 5;
    node[102]->nn_param.pool.stride[0] = 1;
    node[102]->nn_param.pool.stride[1] = 1;
    node[102]->nn_param.pool.pad[0] = 0;
    node[102]->nn_param.pool.pad[1] = 0;
    node[102]->nn_param.pool.pad[2] = 0;
    node[102]->nn_param.pool.pad[3] = 0;
    node[102]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_AVG;
    node[102]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[102]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/1/se_module/fc1/Conv_output_0_26
      var       - node[103]
      name      - conv_5/model/1/se_module/fc1/Conv_output_0
      operation - convolution
      input     - [1, 1, 128, 1]
      filter    - [1, 1, 128, 32]
      output    - [1, 1, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[103], VSI_NN_OP_CONV2D, 3, 1, 26);
    node[103]->nn_param.conv2d.ksize[0] = 1;
    node[103]->nn_param.conv2d.ksize[1] = 1;
    node[103]->nn_param.conv2d.weights = 32;
    node[103]->nn_param.conv2d.stride[0] = 1;
    node[103]->nn_param.conv2d.stride[1] = 1;
    node[103]->nn_param.conv2d.pad[0] = 0;
    node[103]->nn_param.conv2d.pad[1] = 0;
    node[103]->nn_param.conv2d.pad[2] = 0;
    node[103]->nn_param.conv2d.pad[3] = 0;
    node[103]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[103]->nn_param.conv2d.group = 1;
    node[103]->nn_param.conv2d.dilation[0] = 1;
    node[103]->nn_param.conv2d.dilation[1] = 1;
    node[103]->nn_param.conv2d.multiplier = 0;
    node[103]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[103]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[103]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/1/se_module/relu/Relu_output_0_22
      var       - node[104]
      name      - conv_5/model/1/se_module/relu/Relu_output_0
      operation - relu
      input     - [1, 1, 32, 1]
      output    - [1, 1, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[104], VSI_NN_OP_RELU, 1, 1, 22);

    /*-----------------------------------------
      lid       - conv_5/model/1/se_module/fc2/Conv_output_0_18
      var       - node[105]
      name      - conv_5/model/1/se_module/fc2/Conv_output_0
      operation - convolution
      input     - [1, 1, 32, 1]
      filter    - [1, 1, 32, 128]
      output    - [1, 1, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[105], VSI_NN_OP_CONV2D, 3, 1, 18);
    node[105]->nn_param.conv2d.ksize[0] = 1;
    node[105]->nn_param.conv2d.ksize[1] = 1;
    node[105]->nn_param.conv2d.weights = 128;
    node[105]->nn_param.conv2d.stride[0] = 1;
    node[105]->nn_param.conv2d.stride[1] = 1;
    node[105]->nn_param.conv2d.pad[0] = 0;
    node[105]->nn_param.conv2d.pad[1] = 0;
    node[105]->nn_param.conv2d.pad[2] = 0;
    node[105]->nn_param.conv2d.pad[3] = 0;
    node[105]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[105]->nn_param.conv2d.group = 1;
    node[105]->nn_param.conv2d.dilation[0] = 1;
    node[105]->nn_param.conv2d.dilation[1] = 1;
    node[105]->nn_param.conv2d.multiplier = 0;
    node[105]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[105]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[105]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_5/model/1/se_module/sigmoid/Sigmoid_output_0_14
      var       - node[106]
      name      - conv_5/model/1/se_module/sigmoid/Sigmoid_output_0
      operation - sigmoid
      input     - [1, 1, 128, 1]
      output    - [1, 1, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[106], VSI_NN_OP_SIGMOID, 1, 1, 14);

    /*-----------------------------------------
      lid       - conv_5/model/1/se_module/Mul_output_0_10
      var       - node[107]
      name      - conv_5/model/1/se_module/Mul_output_0
      operation - multiply
      input     - [5, 5, 128, 1]
                  [1, 1, 128, 1]
      output    - [5, 5, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[107], VSI_NN_OP_MULTIPLY, 2, 1, 10);
    node[107]->nn_param.multiply.scale = 1;
    node[107]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[107]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;

    /*-----------------------------------------
      lid       - conv_5/model/1/Add_output_0_8
      var       - node[108]
      name      - conv_5/model/1/Add_output_0
      operation - add
      input     - [5, 5, 128, 1]
                  [5, 5, 128, 1]
      output    - [5, 5, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[108], VSI_NN_OP_ADD, 2, 1, 8);

    /*-----------------------------------------
      lid       - conv_6_sep/conv/Conv_output_0_7
      var       - node[109]
      name      - conv_6_sep/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 128, 1]
      filter    - [1, 1, 128, 512]
      output    - [5, 5, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[109], VSI_NN_OP_CONV2D, 3, 1, 7);
    node[109]->nn_param.conv2d.ksize[0] = 1;
    node[109]->nn_param.conv2d.ksize[1] = 1;
    node[109]->nn_param.conv2d.weights = 512;
    node[109]->nn_param.conv2d.stride[0] = 1;
    node[109]->nn_param.conv2d.stride[1] = 1;
    node[109]->nn_param.conv2d.pad[0] = 0;
    node[109]->nn_param.conv2d.pad[1] = 0;
    node[109]->nn_param.conv2d.pad[2] = 0;
    node[109]->nn_param.conv2d.pad[3] = 0;
    node[109]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[109]->nn_param.conv2d.group = 1;
    node[109]->nn_param.conv2d.dilation[0] = 1;
    node[109]->nn_param.conv2d.dilation[1] = 1;
    node[109]->nn_param.conv2d.multiplier = 0;
    node[109]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[109]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[109]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_6_sep/prelu/PRelu_output_0_6
      var       - node[110]
      name      - conv_6_sep/prelu/PRelu_output_0
      operation - prelu
      input     - [5, 5, 512, 1]
      output    - [5, 5, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[110], VSI_NN_OP_PRELU, 2, 1, 6);

    /*-----------------------------------------
      lid       - conv_6_dw/conv/Conv_output_0_5
      var       - node[111]
      name      - conv_6_dw/conv/Conv_output_0
      operation - convolution
      input     - [5, 5, 512, 1]
      filter    - [5, 5, 512, 1]
      output    - [1, 1, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[111], VSI_NN_OP_CONV2D, 3, 1, 5);
    node[111]->nn_param.conv2d.ksize[0] = 5;
    node[111]->nn_param.conv2d.ksize[1] = 5;
    node[111]->nn_param.conv2d.weights = 512;
    node[111]->nn_param.conv2d.stride[0] = 1;
    node[111]->nn_param.conv2d.stride[1] = 1;
    node[111]->nn_param.conv2d.pad[0] = 0;
    node[111]->nn_param.conv2d.pad[1] = 0;
    node[111]->nn_param.conv2d.pad[2] = 0;
    node[111]->nn_param.conv2d.pad[3] = 0;
    node[111]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[111]->nn_param.conv2d.group = 512;
    node[111]->nn_param.conv2d.dilation[0] = 1;
    node[111]->nn_param.conv2d.dilation[1] = 1;
    node[111]->nn_param.conv2d.multiplier = 1;
    node[111]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[111]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[111]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - conv_6_flatten/Reshape_output_0_4
      var       - node[112]
      name      - conv_6_flatten/Reshape_output_0
      operation - reshape
      input     - [1, 1, 512, 1]
      output    - [512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[112], VSI_NN_OP_RESHAPE2, 1, 1, 4);
    node[112]->nn_param.reshape2.size = shape_1;
    node[112]->nn_param.reshape2.dim_num = 2;

    /*-----------------------------------------
      lid       - linear/MatMul_output_0_3
      var       - node[113]
      name      - linear/MatMul_output_0
      operation - fullconnect
      input     - [512, 1]
      filter    - [512, 128]
      output    - [128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[113], VSI_NN_OP_FCL, 3, 1, 3);
    node[113]->nn_param.fcl.weights = 128;
    node[113]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[113]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[113]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - output_1
      var       - node[114]
      name      - output
      operation - fullconnect
      input     - [128, 1]
      filter    - [128, 3]
      output    - [3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[114], VSI_NN_OP_FCL, 3, 1, 1);
    node[114]->nn_param.fcl.weights = 3;
    node[114]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[114]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[114]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    }
    else
    {
    NEW_VXNODE(node[0], VSI_NN_OP_NBG, 1, 1, 0);
    node[0]->nn_param.nbg.type = VSI_NN_NBG_FILE;
    node[0]->nn_param.nbg.url = data_file_name;

    }

/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @attach_output/out0_0:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @input_117:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 80;
    attr.size[1] = 80;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_FLOAT16);



    if( !inference_with_nbg )
    {
    /* @conv1/conv/Conv_output_0_116:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 3;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_FLOAT16, 128, 1728);

    /* @conv1/conv/Conv_output_0_116:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_FLOAT32, 0, 128);

    /* @conv1/prelu/PRelu_output_0_115:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_FLOAT16, 1856, 64);

    /* @conv2_dw/conv/Conv_output_0_114:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_FLOAT16, 2048, 576);

    /* @conv2_dw/conv/Conv_output_0_114:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_FLOAT32, 1920, 128);

    /* @conv2_dw/prelu/PRelu_output_0_113:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_FLOAT16, 2624, 64);

    /* @conv_23/conv/conv/Conv_output_0_112:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 103;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_FLOAT16, 3100, 6592);

    /* @conv_23/conv/conv/Conv_output_0_112:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 103;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_FLOAT32, 2688, 412);

    /* @conv_23/conv/prelu/PRelu_output_0_108:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 103;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_FLOAT16, 9692, 206);

    /* @conv_23/conv_dw/conv/Conv_output_0_102:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 103;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_FLOAT16, 10310, 1854);

    /* @conv_23/conv_dw/conv/Conv_output_0_102:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 103;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_FLOAT32, 9898, 412);

    /* @conv_23/conv_dw/prelu/PRelu_output_0_96:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 103;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_FLOAT16, 12164, 206);

    /* @conv_23/project/conv/Conv_output_0_90:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 103;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_FLOAT16, 12626, 13184);

    /* @conv_23/project/conv/Conv_output_0_90:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_FLOAT32, 12370, 256);

    /* @conv_3/model/0/conv/conv/Conv_output_0_111:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 13;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_FLOAT16, 25862, 1664);

    /* @conv_3/model/0/conv/conv/Conv_output_0_111:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 13;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_FLOAT32, 25810, 52);

    /* @conv_3/model/0/conv/prelu/PRelu_output_0_109:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 13;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_FLOAT16, 27526, 26);

    /* @conv_3/model/0/conv_dw/conv/Conv_output_0_103:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 13;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_FLOAT16, 27604, 234);

    /* @conv_3/model/0/conv_dw/conv/Conv_output_0_103:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 13;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_FLOAT32, 27552, 52);

    /* @conv_3/model/0/conv_dw/prelu/PRelu_output_0_97:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 13;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_FLOAT16, 27838, 26);

    /* @conv_3/model/0/project/conv/Conv_output_0_91:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 13;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_FLOAT16, 28120, 1664);

    /* @conv_3/model/0/project/conv/Conv_output_0_91:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_FLOAT32, 27864, 256);

    /* @conv_3/model/1/conv/conv/Conv_output_0_110:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 26;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_FLOAT16, 29888, 3328);

    /* @conv_3/model/1/conv/conv/Conv_output_0_110:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_FLOAT32, 29784, 104);

    /* @conv_3/model/1/conv/prelu/PRelu_output_0_104:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_FLOAT16, 33216, 52);

    /* @conv_3/model/1/conv_dw/conv/Conv_output_0_98:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_FLOAT16, 33372, 468);

    /* @conv_3/model/1/conv_dw/conv/Conv_output_0_98:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_FLOAT32, 33268, 104);

    /* @conv_3/model/1/conv_dw/prelu/PRelu_output_0_92:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_FLOAT16, 33840, 52);

    /* @conv_3/model/1/project/conv/Conv_output_0_86:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_FLOAT16, 34148, 3328);

    /* @conv_3/model/1/project/conv/Conv_output_0_86:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_FLOAT32, 33892, 256);

    /* @conv_3/model/2/conv/conv/Conv_output_0_105:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 13;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_FLOAT16, 37528, 1664);

    /* @conv_3/model/2/conv/conv/Conv_output_0_105:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 13;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_FLOAT32, 37476, 52);

    /* @conv_3/model/2/conv/prelu/PRelu_output_0_99:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 13;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_FLOAT16, 39192, 26);

    /* @conv_3/model/2/conv_dw/conv/Conv_output_0_93:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 13;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_FLOAT16, 39270, 234);

    /* @conv_3/model/2/conv_dw/conv/Conv_output_0_93:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 13;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_FLOAT32, 39218, 52);

    /* @conv_3/model/2/conv_dw/prelu/PRelu_output_0_87:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 13;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_FLOAT16, 39504, 26);

    /* @conv_3/model/2/project/conv/Conv_output_0_82:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 13;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_FLOAT16, 39786, 1664);

    /* @conv_3/model/2/project/conv/Conv_output_0_82:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_FLOAT32, 39530, 256);

    /* @conv_3/model/3/conv/conv/Conv_output_0_106:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 52;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_FLOAT16, 41658, 6656);

    /* @conv_3/model/3/conv/conv/Conv_output_0_106:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 52;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_FLOAT32, 41450, 208);

    /* @conv_3/model/3/conv/prelu/PRelu_output_0_100:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_FLOAT16, 48314, 104);

    /* @conv_3/model/3/conv_dw/conv/Conv_output_0_94:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_FLOAT16, 48626, 936);

    /* @conv_3/model/3/conv_dw/conv/Conv_output_0_94:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 52;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_FLOAT32, 48418, 208);

    /* @conv_3/model/3/conv_dw/prelu/PRelu_output_0_88:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_FLOAT16, 49562, 104);

    /* @conv_3/model/3/project/conv/Conv_output_0_83:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_FLOAT16, 49922, 6656);

    /* @conv_3/model/3/project/conv/Conv_output_0_83:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_FLOAT32, 49666, 256);

    /* @conv_3/model/3/se_module/fc1/Conv_output_0_101:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 16;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_FLOAT16, 56642, 2048);

    /* @conv_3/model/3/se_module/fc1/Conv_output_0_101:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 16;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_FLOAT32, 56578, 64);

    /* @conv_3/model/3/se_module/fc2/Conv_output_0_89:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 16;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_FLOAT16, 58946, 2048);

    /* @conv_3/model/3/se_module/fc2/Conv_output_0_89:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_FLOAT32, 58690, 256);

    /* @conv_34/conv/conv/Conv_output_0_77:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 231;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_FLOAT16, 61918, 29568);

    /* @conv_34/conv/conv/Conv_output_0_77:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 231;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_FLOAT32, 60994, 924);

    /* @conv_34/conv/prelu/PRelu_output_0_74:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 231;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[52], attr, VSI_NN_TYPE_FLOAT16, 91486, 462);

    /* @conv_34/conv_dw/conv/Conv_output_0_70:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 231;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[53], attr, VSI_NN_TYPE_FLOAT16, 92872, 4158);

    /* @conv_34/conv_dw/conv/Conv_output_0_70:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 231;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[54], attr, VSI_NN_TYPE_FLOAT32, 91948, 924);

    /* @conv_34/conv_dw/prelu/PRelu_output_0_65:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 231;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[55], attr, VSI_NN_TYPE_FLOAT16, 97030, 462);

    /* @conv_34/project/conv/Conv_output_0_59:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 231;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[56], attr, VSI_NN_TYPE_FLOAT16, 98004, 59136);

    /* @conv_34/project/conv/Conv_output_0_59:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[57], attr, VSI_NN_TYPE_FLOAT32, 97492, 512);

    /* @conv_4/model/0/conv/conv/Conv_output_0_76:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 154;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[58], attr, VSI_NN_TYPE_FLOAT16, 157756, 39424);

    /* @conv_4/model/0/conv/conv/Conv_output_0_76:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 154;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[59], attr, VSI_NN_TYPE_FLOAT32, 157140, 616);

    /* @conv_4/model/0/conv/prelu/PRelu_output_0_75:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 154;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[60], attr, VSI_NN_TYPE_FLOAT16, 197180, 308);

    /* @conv_4/model/0/conv_dw/conv/Conv_output_0_71:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 154;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[61], attr, VSI_NN_TYPE_FLOAT16, 198104, 2772);

    /* @conv_4/model/0/conv_dw/conv/Conv_output_0_71:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 154;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[62], attr, VSI_NN_TYPE_FLOAT32, 197488, 616);

    /* @conv_4/model/0/conv_dw/prelu/PRelu_output_0_66:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 154;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[63], attr, VSI_NN_TYPE_FLOAT16, 200876, 308);

    /* @conv_4/model/0/project/conv/Conv_output_0_60:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 154;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[64], attr, VSI_NN_TYPE_FLOAT16, 201696, 39424);

    /* @conv_4/model/0/project/conv/Conv_output_0_60:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[65], attr, VSI_NN_TYPE_FLOAT32, 201184, 512);

    /* @conv_4/model/1/conv/conv/Conv_output_0_73:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 52;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[66], attr, VSI_NN_TYPE_FLOAT16, 241328, 13312);

    /* @conv_4/model/1/conv/conv/Conv_output_0_73:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 52;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[67], attr, VSI_NN_TYPE_FLOAT32, 241120, 208);

    /* @conv_4/model/1/conv/prelu/PRelu_output_0_72:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[68], attr, VSI_NN_TYPE_FLOAT16, 254640, 104);

    /* @conv_4/model/1/conv_dw/conv/Conv_output_0_67:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[69], attr, VSI_NN_TYPE_FLOAT16, 254952, 936);

    /* @conv_4/model/1/conv_dw/conv/Conv_output_0_67:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 52;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[70], attr, VSI_NN_TYPE_FLOAT32, 254744, 208);

    /* @conv_4/model/1/conv_dw/prelu/PRelu_output_0_61:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[71], attr, VSI_NN_TYPE_FLOAT16, 255888, 104);

    /* @conv_4/model/1/project/conv/Conv_output_0_54:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[72], attr, VSI_NN_TYPE_FLOAT16, 256504, 13312);

    /* @conv_4/model/1/project/conv/Conv_output_0_54:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[73], attr, VSI_NN_TYPE_FLOAT32, 255992, 512);

    /* @conv_4/model/2/conv/conv/Conv_output_0_69:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 26;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[74], attr, VSI_NN_TYPE_FLOAT16, 269920, 6656);

    /* @conv_4/model/2/conv/conv/Conv_output_0_69:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[75], attr, VSI_NN_TYPE_FLOAT32, 269816, 104);

    /* @conv_4/model/2/conv/prelu/PRelu_output_0_68:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[76], attr, VSI_NN_TYPE_FLOAT16, 276576, 52);

    /* @conv_4/model/2/conv_dw/conv/Conv_output_0_62:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[77], attr, VSI_NN_TYPE_FLOAT16, 276732, 468);

    /* @conv_4/model/2/conv_dw/conv/Conv_output_0_62:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[78], attr, VSI_NN_TYPE_FLOAT32, 276628, 104);

    /* @conv_4/model/2/conv_dw/prelu/PRelu_output_0_55:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[79], attr, VSI_NN_TYPE_FLOAT16, 277200, 52);

    /* @conv_4/model/2/project/conv/Conv_output_0_48:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[80], attr, VSI_NN_TYPE_FLOAT16, 277764, 6656);

    /* @conv_4/model/2/project/conv/Conv_output_0_48:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[81], attr, VSI_NN_TYPE_FLOAT32, 277252, 512);

    /* @conv_4/model/3/conv/conv/Conv_output_0_64:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 52;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[82], attr, VSI_NN_TYPE_FLOAT16, 284628, 13312);

    /* @conv_4/model/3/conv/conv/Conv_output_0_64:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 52;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[83], attr, VSI_NN_TYPE_FLOAT32, 284420, 208);

    /* @conv_4/model/3/conv/prelu/PRelu_output_0_63:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[84], attr, VSI_NN_TYPE_FLOAT16, 297940, 104);

    /* @conv_4/model/3/conv_dw/conv/Conv_output_0_56:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[85], attr, VSI_NN_TYPE_FLOAT16, 298252, 936);

    /* @conv_4/model/3/conv_dw/conv/Conv_output_0_56:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 52;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[86], attr, VSI_NN_TYPE_FLOAT32, 298044, 208);

    /* @conv_4/model/3/conv_dw/prelu/PRelu_output_0_49:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[87], attr, VSI_NN_TYPE_FLOAT16, 299188, 104);

    /* @conv_4/model/3/project/conv/Conv_output_0_43:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 52;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[88], attr, VSI_NN_TYPE_FLOAT16, 299804, 13312);

    /* @conv_4/model/3/project/conv/Conv_output_0_43:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[89], attr, VSI_NN_TYPE_FLOAT32, 299292, 512);

    /* @conv_4/model/4/conv/conv/Conv_output_0_58:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 26;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[90], attr, VSI_NN_TYPE_FLOAT16, 313220, 6656);

    /* @conv_4/model/4/conv/conv/Conv_output_0_58:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[91], attr, VSI_NN_TYPE_FLOAT32, 313116, 104);

    /* @conv_4/model/4/conv/prelu/PRelu_output_0_57:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[92], attr, VSI_NN_TYPE_FLOAT16, 319876, 52);

    /* @conv_4/model/4/conv_dw/conv/Conv_output_0_50:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[93], attr, VSI_NN_TYPE_FLOAT16, 320032, 468);

    /* @conv_4/model/4/conv_dw/conv/Conv_output_0_50:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[94], attr, VSI_NN_TYPE_FLOAT32, 319928, 104);

    /* @conv_4/model/4/conv_dw/prelu/PRelu_output_0_44:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[95], attr, VSI_NN_TYPE_FLOAT16, 320500, 52);

    /* @conv_4/model/4/project/conv/Conv_output_0_39:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[96], attr, VSI_NN_TYPE_FLOAT16, 321064, 6656);

    /* @conv_4/model/4/project/conv/Conv_output_0_39:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[97], attr, VSI_NN_TYPE_FLOAT32, 320552, 512);

    /* @conv_4/model/5/conv/conv/Conv_output_0_52:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 26;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[98], attr, VSI_NN_TYPE_FLOAT16, 327824, 6656);

    /* @conv_4/model/5/conv/conv/Conv_output_0_52:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[99], attr, VSI_NN_TYPE_FLOAT32, 327720, 104);

    /* @conv_4/model/5/conv/prelu/PRelu_output_0_51:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[100], attr, VSI_NN_TYPE_FLOAT16, 334480, 52);

    /* @conv_4/model/5/conv_dw/conv/Conv_output_0_45:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[101], attr, VSI_NN_TYPE_FLOAT16, 334636, 468);

    /* @conv_4/model/5/conv_dw/conv/Conv_output_0_45:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[102], attr, VSI_NN_TYPE_FLOAT32, 334532, 104);

    /* @conv_4/model/5/conv_dw/prelu/PRelu_output_0_40:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[103], attr, VSI_NN_TYPE_FLOAT16, 335104, 52);

    /* @conv_4/model/5/project/conv/Conv_output_0_36:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[104], attr, VSI_NN_TYPE_FLOAT16, 335668, 6656);

    /* @conv_4/model/5/project/conv/Conv_output_0_36:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[105], attr, VSI_NN_TYPE_FLOAT32, 335156, 512);

    /* @conv_4/model/5/se_module/fc1/Conv_output_0_41:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[106], attr, VSI_NN_TYPE_FLOAT16, 342452, 8192);

    /* @conv_4/model/5/se_module/fc1/Conv_output_0_41:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[107], attr, VSI_NN_TYPE_FLOAT32, 342324, 128);

    /* @conv_4/model/5/se_module/fc2/Conv_output_0_34:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[108], attr, VSI_NN_TYPE_FLOAT16, 351156, 8192);

    /* @conv_4/model/5/se_module/fc2/Conv_output_0_34:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[109], attr, VSI_NN_TYPE_FLOAT32, 350644, 512);

    /* @conv_45/conv/conv/Conv_output_0_27:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 308;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[110], attr, VSI_NN_TYPE_FLOAT16, 360580, 78848);

    /* @conv_45/conv/conv/Conv_output_0_27:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 308;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[111], attr, VSI_NN_TYPE_FLOAT32, 359348, 1232);

    /* @conv_45/conv/prelu/PRelu_output_0_23:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 308;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[112], attr, VSI_NN_TYPE_FLOAT16, 439428, 616);

    /* @conv_45/conv_dw/conv/Conv_output_0_19:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 308;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[113], attr, VSI_NN_TYPE_FLOAT16, 441276, 5544);

    /* @conv_45/conv_dw/conv/Conv_output_0_19:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 308;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[114], attr, VSI_NN_TYPE_FLOAT32, 440044, 1232);

    /* @conv_45/conv_dw/prelu/PRelu_output_0_15:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 308;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[115], attr, VSI_NN_TYPE_FLOAT16, 446820, 616);

    /* @conv_45/project/conv/Conv_output_0_11:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 308;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[116], attr, VSI_NN_TYPE_FLOAT16, 447948, 78848);

    /* @conv_45/project/conv/Conv_output_0_11:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[117], attr, VSI_NN_TYPE_FLOAT32, 447436, 512);

    /* @conv_5/model/0/conv/conv/Conv_output_0_28:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 26;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[118], attr, VSI_NN_TYPE_FLOAT16, 526900, 6656);

    /* @conv_5/model/0/conv/conv/Conv_output_0_28:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[119], attr, VSI_NN_TYPE_FLOAT32, 526796, 104);

    /* @conv_5/model/0/conv/prelu/PRelu_output_0_24:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[120], attr, VSI_NN_TYPE_FLOAT16, 533556, 52);

    /* @conv_5/model/0/conv_dw/conv/Conv_output_0_20:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[121], attr, VSI_NN_TYPE_FLOAT16, 533712, 468);

    /* @conv_5/model/0/conv_dw/conv/Conv_output_0_20:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[122], attr, VSI_NN_TYPE_FLOAT32, 533608, 104);

    /* @conv_5/model/0/conv_dw/prelu/PRelu_output_0_16:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[123], attr, VSI_NN_TYPE_FLOAT16, 534180, 52);

    /* @conv_5/model/0/project/conv/Conv_output_0_12:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[124], attr, VSI_NN_TYPE_FLOAT16, 534744, 6656);

    /* @conv_5/model/0/project/conv/Conv_output_0_12:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[125], attr, VSI_NN_TYPE_FLOAT32, 534232, 512);

    /* @conv_5/model/1/conv/conv/Conv_output_0_29:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 26;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[126], attr, VSI_NN_TYPE_FLOAT16, 541504, 6656);

    /* @conv_5/model/1/conv/conv/Conv_output_0_29:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[127], attr, VSI_NN_TYPE_FLOAT32, 541400, 104);

    /* @conv_5/model/1/conv/prelu/PRelu_output_0_25:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[128], attr, VSI_NN_TYPE_FLOAT16, 548160, 52);

    /* @conv_5/model/1/conv_dw/conv/Conv_output_0_21:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[129], attr, VSI_NN_TYPE_FLOAT16, 548316, 468);

    /* @conv_5/model/1/conv_dw/conv/Conv_output_0_21:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 26;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[130], attr, VSI_NN_TYPE_FLOAT32, 548212, 104);

    /* @conv_5/model/1/conv_dw/prelu/PRelu_output_0_17:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[131], attr, VSI_NN_TYPE_FLOAT16, 548784, 52);

    /* @conv_5/model/1/project/conv/Conv_output_0_13:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 26;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[132], attr, VSI_NN_TYPE_FLOAT16, 549348, 6656);

    /* @conv_5/model/1/project/conv/Conv_output_0_13:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[133], attr, VSI_NN_TYPE_FLOAT32, 548836, 512);

    /* @conv_5/model/1/se_module/fc1/Conv_output_0_26:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[134], attr, VSI_NN_TYPE_FLOAT16, 556132, 8192);

    /* @conv_5/model/1/se_module/fc1/Conv_output_0_26:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[135], attr, VSI_NN_TYPE_FLOAT32, 556004, 128);

    /* @conv_5/model/1/se_module/fc2/Conv_output_0_18:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[136], attr, VSI_NN_TYPE_FLOAT16, 564836, 8192);

    /* @conv_5/model/1/se_module/fc2/Conv_output_0_18:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[137], attr, VSI_NN_TYPE_FLOAT32, 564324, 512);

    /* @conv_6_sep/conv/Conv_output_0_7:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[138], attr, VSI_NN_TYPE_FLOAT16, 602724, 131072);

    /* @conv_6_sep/conv/Conv_output_0_7:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[139], attr, VSI_NN_TYPE_FLOAT32, 600676, 2048);

    /* @conv_6_sep/prelu/PRelu_output_0_6:a */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[140], attr, VSI_NN_TYPE_FLOAT16, 733796, 1024);

    /* @conv_6_dw/conv/Conv_output_0_5:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 5;
    attr.size[1] = 5;
    attr.size[2] = 512;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[141], attr, VSI_NN_TYPE_FLOAT16, 575076, 25600);

    /* @conv_6_dw/conv/Conv_output_0_5:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[142], attr, VSI_NN_TYPE_FLOAT32, 573028, 2048);

    /* @linear/MatMul_output_0_3:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.size[1] = 128;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[143], attr, VSI_NN_TYPE_FLOAT16, 735332, 131072);

    /* @linear/MatMul_output_0_3:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[144], attr, VSI_NN_TYPE_FLOAT32, 734820, 512);

    /* @output_1:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.size[1] = 3;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[145], attr, VSI_NN_TYPE_FLOAT16, 866416, 768);

    /* @output_1:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.dim_num = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[146], attr, VSI_NN_TYPE_FLOAT32, 866404, 12);



    /* @conv1/conv/Conv_output_0_116:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv1/prelu/PRelu_output_0_115:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv2_dw/conv/Conv_output_0_114:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv2_dw/prelu/PRelu_output_0_113:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_23/conv/conv/Conv_output_0_112:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_23/conv/prelu/PRelu_output_0_108:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_23/conv_dw/conv/Conv_output_0_102:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_23/conv_dw/prelu/PRelu_output_0_96:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_23/project/conv/Conv_output_0_90:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/0/conv/conv/Conv_output_0_111:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/0/conv/prelu/PRelu_output_0_109:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/0/conv_dw/conv/Conv_output_0_103:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/0/conv_dw/prelu/PRelu_output_0_97:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/0/project/conv/Conv_output_0_91:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/0/Add_output_0_85:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/1/conv/conv/Conv_output_0_110:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/1/conv/prelu/PRelu_output_0_104:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/1/conv_dw/conv/Conv_output_0_98:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/1/conv_dw/prelu/PRelu_output_0_92:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/1/project/conv/Conv_output_0_86:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/1/Add_output_0_81:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/2/conv/conv/Conv_output_0_105:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/2/conv/prelu/PRelu_output_0_99:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/2/conv_dw/conv/Conv_output_0_93:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/2/conv_dw/prelu/PRelu_output_0_87:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/2/project/conv/Conv_output_0_82:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/2/Add_output_0_79:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/conv/conv/Conv_output_0_106:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/conv/prelu/PRelu_output_0_100:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/conv_dw/conv/Conv_output_0_94:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/conv_dw/prelu/PRelu_output_0_88:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/project/conv/Conv_output_0_83:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/se_module/avg_pool/GlobalAveragePool_output_0_107:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[32]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/se_module/fc1/Conv_output_0_101:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[33]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/se_module/relu/Relu_output_0_95:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[34]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/se_module/fc2/Conv_output_0_89:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[35]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/se_module/sigmoid/Sigmoid_output_0_84:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[36]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/se_module/Mul_output_0_80:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[37]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_3/model/3/Add_output_0_78:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[38]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_34/conv/conv/Conv_output_0_77:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[39]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_34/conv/prelu/PRelu_output_0_74:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[40]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_34/conv_dw/conv/Conv_output_0_70:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[41]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_34/conv_dw/prelu/PRelu_output_0_65:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[42]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_34/project/conv/Conv_output_0_59:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[43]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/0/conv/conv/Conv_output_0_76:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[44]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/0/conv/prelu/PRelu_output_0_75:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[45]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/0/conv_dw/conv/Conv_output_0_71:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[46]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/0/conv_dw/prelu/PRelu_output_0_66:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[47]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/0/project/conv/Conv_output_0_60:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[48]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/0/Add_output_0_53:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[49]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/1/conv/conv/Conv_output_0_73:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[50]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/1/conv/prelu/PRelu_output_0_72:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[51]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/1/conv_dw/conv/Conv_output_0_67:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[52]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/1/conv_dw/prelu/PRelu_output_0_61:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[53]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/1/project/conv/Conv_output_0_54:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[54]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/1/Add_output_0_47:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[55]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/2/conv/conv/Conv_output_0_69:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[56]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/2/conv/prelu/PRelu_output_0_68:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[57]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/2/conv_dw/conv/Conv_output_0_62:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[58]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/2/conv_dw/prelu/PRelu_output_0_55:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[59]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/2/project/conv/Conv_output_0_48:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[60]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/2/Add_output_0_42:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[61]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/3/conv/conv/Conv_output_0_64:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[62]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/3/conv/prelu/PRelu_output_0_63:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[63]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/3/conv_dw/conv/Conv_output_0_56:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[64]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/3/conv_dw/prelu/PRelu_output_0_49:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[65]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/3/project/conv/Conv_output_0_43:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[66]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/3/Add_output_0_38:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[67]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/4/conv/conv/Conv_output_0_58:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[68]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/4/conv/prelu/PRelu_output_0_57:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[69]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/4/conv_dw/conv/Conv_output_0_50:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[70]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/4/conv_dw/prelu/PRelu_output_0_44:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[71]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/4/project/conv/Conv_output_0_39:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[72]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/4/Add_output_0_35:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[73]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/conv/conv/Conv_output_0_52:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[74]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/conv/prelu/PRelu_output_0_51:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[75]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/conv_dw/conv/Conv_output_0_45:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[76]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/conv_dw/prelu/PRelu_output_0_40:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[77]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/project/conv/Conv_output_0_36:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[78]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/se_module/avg_pool/GlobalAveragePool_output_0_46:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[79]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/se_module/fc1/Conv_output_0_41:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[80]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/se_module/relu/Relu_output_0_37:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[81]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/se_module/fc2/Conv_output_0_34:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[82]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/se_module/sigmoid/Sigmoid_output_0_33:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[83]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/se_module/Mul_output_0_32:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[84]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_4/model/5/Add_output_0_31:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[85]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_45/conv/conv/Conv_output_0_27:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[86]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_45/conv/prelu/PRelu_output_0_23:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[87]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_45/conv_dw/conv/Conv_output_0_19:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[88]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_45/conv_dw/prelu/PRelu_output_0_15:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[89]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_45/project/conv/Conv_output_0_11:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[90]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/0/conv/conv/Conv_output_0_28:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[91]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/0/conv/prelu/PRelu_output_0_24:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[92]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/0/conv_dw/conv/Conv_output_0_20:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[93]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/0/conv_dw/prelu/PRelu_output_0_16:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[94]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/0/project/conv/Conv_output_0_12:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[95]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/0/Add_output_0_9:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[96]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/conv/conv/Conv_output_0_29:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[97]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/conv/prelu/PRelu_output_0_25:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[98]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/conv_dw/conv/Conv_output_0_21:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[99]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/conv_dw/prelu/PRelu_output_0_17:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[100]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/project/conv/Conv_output_0_13:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[101]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/se_module/avg_pool/GlobalAveragePool_output_0_30:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[102]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/se_module/fc1/Conv_output_0_26:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[103]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/se_module/relu/Relu_output_0_22:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[104]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/se_module/fc2/Conv_output_0_18:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[105]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/se_module/sigmoid/Sigmoid_output_0_14:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[106]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/se_module/Mul_output_0_10:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[107]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_5/model/1/Add_output_0_8:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[108]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_6_sep/conv/Conv_output_0_7:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[109]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_6_sep/prelu/PRelu_output_0_6:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[110]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_6_dw/conv/Conv_output_0_5:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[111]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @conv_6_flatten/Reshape_output_0_4:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[112]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);

    /* @linear/MatMul_output_0_3:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_VIRTUAL_TENSOR(node[113]->output.tensors[0], attr, VSI_NN_TYPE_FLOAT16);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[0]->input.tensors[0] = norm_tensor[1];
    node[114]->output.tensors[0] = norm_tensor[0];

    /* conv1/conv/Conv_output_0_116 */
    node[0]->input.tensors[1] = const_tensor[0]; /* data_weight */
    node[0]->input.tensors[2] = const_tensor[1]; /* data_bias */

    /* conv1/prelu/PRelu_output_0_115 */
    node[1]->input.tensors[0] = node[0]->output.tensors[0];
    node[1]->input.tensors[1] = const_tensor[2]; /* data_a */

    /* conv2_dw/conv/Conv_output_0_114 */
    node[2]->input.tensors[0] = node[1]->output.tensors[0];
    node[2]->input.tensors[1] = const_tensor[3]; /* data_weight */
    node[2]->input.tensors[2] = const_tensor[4]; /* data_bias */

    /* conv2_dw/prelu/PRelu_output_0_113 */
    node[3]->input.tensors[0] = node[2]->output.tensors[0];
    node[3]->input.tensors[1] = const_tensor[5]; /* data_a */

    /* conv_23/conv/conv/Conv_output_0_112 */
    node[4]->input.tensors[0] = node[3]->output.tensors[0];
    node[4]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[4]->input.tensors[2] = const_tensor[7]; /* data_bias */

    /* conv_23/conv/prelu/PRelu_output_0_108 */
    node[5]->input.tensors[0] = node[4]->output.tensors[0];
    node[5]->input.tensors[1] = const_tensor[8]; /* data_a */

    /* conv_23/conv_dw/conv/Conv_output_0_102 */
    node[6]->input.tensors[0] = node[5]->output.tensors[0];
    node[6]->input.tensors[1] = const_tensor[9]; /* data_weight */
    node[6]->input.tensors[2] = const_tensor[10]; /* data_bias */

    /* conv_23/conv_dw/prelu/PRelu_output_0_96 */
    node[7]->input.tensors[0] = node[6]->output.tensors[0];
    node[7]->input.tensors[1] = const_tensor[11]; /* data_a */

    /* conv_23/project/conv/Conv_output_0_90 */
    node[8]->input.tensors[0] = node[7]->output.tensors[0];
    node[8]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[8]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* conv_3/model/0/conv/conv/Conv_output_0_111 */
    node[9]->input.tensors[0] = node[8]->output.tensors[0];
    node[9]->input.tensors[1] = const_tensor[14]; /* data_weight */
    node[9]->input.tensors[2] = const_tensor[15]; /* data_bias */

    /* conv_3/model/0/conv/prelu/PRelu_output_0_109 */
    node[10]->input.tensors[0] = node[9]->output.tensors[0];
    node[10]->input.tensors[1] = const_tensor[16]; /* data_a */

    /* conv_3/model/0/conv_dw/conv/Conv_output_0_103 */
    node[11]->input.tensors[0] = node[10]->output.tensors[0];
    node[11]->input.tensors[1] = const_tensor[17]; /* data_weight */
    node[11]->input.tensors[2] = const_tensor[18]; /* data_bias */

    /* conv_3/model/0/conv_dw/prelu/PRelu_output_0_97 */
    node[12]->input.tensors[0] = node[11]->output.tensors[0];
    node[12]->input.tensors[1] = const_tensor[19]; /* data_a */

    /* conv_3/model/0/project/conv/Conv_output_0_91 */
    node[13]->input.tensors[0] = node[12]->output.tensors[0];
    node[13]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[13]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* conv_3/model/0/Add_output_0_85 */
    node[14]->input.tensors[0] = node[8]->output.tensors[0];
    node[14]->input.tensors[1] = node[13]->output.tensors[0];

    /* conv_3/model/1/conv/conv/Conv_output_0_110 */
    node[15]->input.tensors[0] = node[14]->output.tensors[0];
    node[15]->input.tensors[1] = const_tensor[22]; /* data_weight */
    node[15]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* conv_3/model/1/conv/prelu/PRelu_output_0_104 */
    node[16]->input.tensors[0] = node[15]->output.tensors[0];
    node[16]->input.tensors[1] = const_tensor[24]; /* data_a */

    /* conv_3/model/1/conv_dw/conv/Conv_output_0_98 */
    node[17]->input.tensors[0] = node[16]->output.tensors[0];
    node[17]->input.tensors[1] = const_tensor[25]; /* data_weight */
    node[17]->input.tensors[2] = const_tensor[26]; /* data_bias */

    /* conv_3/model/1/conv_dw/prelu/PRelu_output_0_92 */
    node[18]->input.tensors[0] = node[17]->output.tensors[0];
    node[18]->input.tensors[1] = const_tensor[27]; /* data_a */

    /* conv_3/model/1/project/conv/Conv_output_0_86 */
    node[19]->input.tensors[0] = node[18]->output.tensors[0];
    node[19]->input.tensors[1] = const_tensor[28]; /* data_weight */
    node[19]->input.tensors[2] = const_tensor[29]; /* data_bias */

    /* conv_3/model/1/Add_output_0_81 */
    node[20]->input.tensors[0] = node[14]->output.tensors[0];
    node[20]->input.tensors[1] = node[19]->output.tensors[0];

    /* conv_3/model/2/conv/conv/Conv_output_0_105 */
    node[21]->input.tensors[0] = node[20]->output.tensors[0];
    node[21]->input.tensors[1] = const_tensor[30]; /* data_weight */
    node[21]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* conv_3/model/2/conv/prelu/PRelu_output_0_99 */
    node[22]->input.tensors[0] = node[21]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[32]; /* data_a */

    /* conv_3/model/2/conv_dw/conv/Conv_output_0_93 */
    node[23]->input.tensors[0] = node[22]->output.tensors[0];
    node[23]->input.tensors[1] = const_tensor[33]; /* data_weight */
    node[23]->input.tensors[2] = const_tensor[34]; /* data_bias */

    /* conv_3/model/2/conv_dw/prelu/PRelu_output_0_87 */
    node[24]->input.tensors[0] = node[23]->output.tensors[0];
    node[24]->input.tensors[1] = const_tensor[35]; /* data_a */

    /* conv_3/model/2/project/conv/Conv_output_0_82 */
    node[25]->input.tensors[0] = node[24]->output.tensors[0];
    node[25]->input.tensors[1] = const_tensor[36]; /* data_weight */
    node[25]->input.tensors[2] = const_tensor[37]; /* data_bias */

    /* conv_3/model/2/Add_output_0_79 */
    node[26]->input.tensors[0] = node[20]->output.tensors[0];
    node[26]->input.tensors[1] = node[25]->output.tensors[0];

    /* conv_3/model/3/conv/conv/Conv_output_0_106 */
    node[27]->input.tensors[0] = node[26]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[38]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* conv_3/model/3/conv/prelu/PRelu_output_0_100 */
    node[28]->input.tensors[0] = node[27]->output.tensors[0];
    node[28]->input.tensors[1] = const_tensor[40]; /* data_a */

    /* conv_3/model/3/conv_dw/conv/Conv_output_0_94 */
    node[29]->input.tensors[0] = node[28]->output.tensors[0];
    node[29]->input.tensors[1] = const_tensor[41]; /* data_weight */
    node[29]->input.tensors[2] = const_tensor[42]; /* data_bias */

    /* conv_3/model/3/conv_dw/prelu/PRelu_output_0_88 */
    node[30]->input.tensors[0] = node[29]->output.tensors[0];
    node[30]->input.tensors[1] = const_tensor[43]; /* data_a */

    /* conv_3/model/3/project/conv/Conv_output_0_83 */
    node[31]->input.tensors[0] = node[30]->output.tensors[0];
    node[31]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[31]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* conv_3/model/3/se_module/avg_pool/GlobalAveragePool_output_0_107 */
    node[32]->input.tensors[0] = node[31]->output.tensors[0];

    /* conv_3/model/3/se_module/fc1/Conv_output_0_101 */
    node[33]->input.tensors[0] = node[32]->output.tensors[0];
    node[33]->input.tensors[1] = const_tensor[46]; /* data_weight */
    node[33]->input.tensors[2] = const_tensor[47]; /* data_bias */

    /* conv_3/model/3/se_module/relu/Relu_output_0_95 */
    node[34]->input.tensors[0] = node[33]->output.tensors[0];

    /* conv_3/model/3/se_module/fc2/Conv_output_0_89 */
    node[35]->input.tensors[0] = node[34]->output.tensors[0];
    node[35]->input.tensors[1] = const_tensor[48]; /* data_weight */
    node[35]->input.tensors[2] = const_tensor[49]; /* data_bias */

    /* conv_3/model/3/se_module/sigmoid/Sigmoid_output_0_84 */
    node[36]->input.tensors[0] = node[35]->output.tensors[0];

    /* conv_3/model/3/se_module/Mul_output_0_80 */
    node[37]->input.tensors[0] = node[31]->output.tensors[0];
    node[37]->input.tensors[1] = node[36]->output.tensors[0];

    /* conv_3/model/3/Add_output_0_78 */
    node[38]->input.tensors[0] = node[26]->output.tensors[0];
    node[38]->input.tensors[1] = node[37]->output.tensors[0];

    /* conv_34/conv/conv/Conv_output_0_77 */
    node[39]->input.tensors[0] = node[38]->output.tensors[0];
    node[39]->input.tensors[1] = const_tensor[50]; /* data_weight */
    node[39]->input.tensors[2] = const_tensor[51]; /* data_bias */

    /* conv_34/conv/prelu/PRelu_output_0_74 */
    node[40]->input.tensors[0] = node[39]->output.tensors[0];
    node[40]->input.tensors[1] = const_tensor[52]; /* data_a */

    /* conv_34/conv_dw/conv/Conv_output_0_70 */
    node[41]->input.tensors[0] = node[40]->output.tensors[0];
    node[41]->input.tensors[1] = const_tensor[53]; /* data_weight */
    node[41]->input.tensors[2] = const_tensor[54]; /* data_bias */

    /* conv_34/conv_dw/prelu/PRelu_output_0_65 */
    node[42]->input.tensors[0] = node[41]->output.tensors[0];
    node[42]->input.tensors[1] = const_tensor[55]; /* data_a */

    /* conv_34/project/conv/Conv_output_0_59 */
    node[43]->input.tensors[0] = node[42]->output.tensors[0];
    node[43]->input.tensors[1] = const_tensor[56]; /* data_weight */
    node[43]->input.tensors[2] = const_tensor[57]; /* data_bias */

    /* conv_4/model/0/conv/conv/Conv_output_0_76 */
    node[44]->input.tensors[0] = node[43]->output.tensors[0];
    node[44]->input.tensors[1] = const_tensor[58]; /* data_weight */
    node[44]->input.tensors[2] = const_tensor[59]; /* data_bias */

    /* conv_4/model/0/conv/prelu/PRelu_output_0_75 */
    node[45]->input.tensors[0] = node[44]->output.tensors[0];
    node[45]->input.tensors[1] = const_tensor[60]; /* data_a */

    /* conv_4/model/0/conv_dw/conv/Conv_output_0_71 */
    node[46]->input.tensors[0] = node[45]->output.tensors[0];
    node[46]->input.tensors[1] = const_tensor[61]; /* data_weight */
    node[46]->input.tensors[2] = const_tensor[62]; /* data_bias */

    /* conv_4/model/0/conv_dw/prelu/PRelu_output_0_66 */
    node[47]->input.tensors[0] = node[46]->output.tensors[0];
    node[47]->input.tensors[1] = const_tensor[63]; /* data_a */

    /* conv_4/model/0/project/conv/Conv_output_0_60 */
    node[48]->input.tensors[0] = node[47]->output.tensors[0];
    node[48]->input.tensors[1] = const_tensor[64]; /* data_weight */
    node[48]->input.tensors[2] = const_tensor[65]; /* data_bias */

    /* conv_4/model/0/Add_output_0_53 */
    node[49]->input.tensors[0] = node[43]->output.tensors[0];
    node[49]->input.tensors[1] = node[48]->output.tensors[0];

    /* conv_4/model/1/conv/conv/Conv_output_0_73 */
    node[50]->input.tensors[0] = node[49]->output.tensors[0];
    node[50]->input.tensors[1] = const_tensor[66]; /* data_weight */
    node[50]->input.tensors[2] = const_tensor[67]; /* data_bias */

    /* conv_4/model/1/conv/prelu/PRelu_output_0_72 */
    node[51]->input.tensors[0] = node[50]->output.tensors[0];
    node[51]->input.tensors[1] = const_tensor[68]; /* data_a */

    /* conv_4/model/1/conv_dw/conv/Conv_output_0_67 */
    node[52]->input.tensors[0] = node[51]->output.tensors[0];
    node[52]->input.tensors[1] = const_tensor[69]; /* data_weight */
    node[52]->input.tensors[2] = const_tensor[70]; /* data_bias */

    /* conv_4/model/1/conv_dw/prelu/PRelu_output_0_61 */
    node[53]->input.tensors[0] = node[52]->output.tensors[0];
    node[53]->input.tensors[1] = const_tensor[71]; /* data_a */

    /* conv_4/model/1/project/conv/Conv_output_0_54 */
    node[54]->input.tensors[0] = node[53]->output.tensors[0];
    node[54]->input.tensors[1] = const_tensor[72]; /* data_weight */
    node[54]->input.tensors[2] = const_tensor[73]; /* data_bias */

    /* conv_4/model/1/Add_output_0_47 */
    node[55]->input.tensors[0] = node[49]->output.tensors[0];
    node[55]->input.tensors[1] = node[54]->output.tensors[0];

    /* conv_4/model/2/conv/conv/Conv_output_0_69 */
    node[56]->input.tensors[0] = node[55]->output.tensors[0];
    node[56]->input.tensors[1] = const_tensor[74]; /* data_weight */
    node[56]->input.tensors[2] = const_tensor[75]; /* data_bias */

    /* conv_4/model/2/conv/prelu/PRelu_output_0_68 */
    node[57]->input.tensors[0] = node[56]->output.tensors[0];
    node[57]->input.tensors[1] = const_tensor[76]; /* data_a */

    /* conv_4/model/2/conv_dw/conv/Conv_output_0_62 */
    node[58]->input.tensors[0] = node[57]->output.tensors[0];
    node[58]->input.tensors[1] = const_tensor[77]; /* data_weight */
    node[58]->input.tensors[2] = const_tensor[78]; /* data_bias */

    /* conv_4/model/2/conv_dw/prelu/PRelu_output_0_55 */
    node[59]->input.tensors[0] = node[58]->output.tensors[0];
    node[59]->input.tensors[1] = const_tensor[79]; /* data_a */

    /* conv_4/model/2/project/conv/Conv_output_0_48 */
    node[60]->input.tensors[0] = node[59]->output.tensors[0];
    node[60]->input.tensors[1] = const_tensor[80]; /* data_weight */
    node[60]->input.tensors[2] = const_tensor[81]; /* data_bias */

    /* conv_4/model/2/Add_output_0_42 */
    node[61]->input.tensors[0] = node[55]->output.tensors[0];
    node[61]->input.tensors[1] = node[60]->output.tensors[0];

    /* conv_4/model/3/conv/conv/Conv_output_0_64 */
    node[62]->input.tensors[0] = node[61]->output.tensors[0];
    node[62]->input.tensors[1] = const_tensor[82]; /* data_weight */
    node[62]->input.tensors[2] = const_tensor[83]; /* data_bias */

    /* conv_4/model/3/conv/prelu/PRelu_output_0_63 */
    node[63]->input.tensors[0] = node[62]->output.tensors[0];
    node[63]->input.tensors[1] = const_tensor[84]; /* data_a */

    /* conv_4/model/3/conv_dw/conv/Conv_output_0_56 */
    node[64]->input.tensors[0] = node[63]->output.tensors[0];
    node[64]->input.tensors[1] = const_tensor[85]; /* data_weight */
    node[64]->input.tensors[2] = const_tensor[86]; /* data_bias */

    /* conv_4/model/3/conv_dw/prelu/PRelu_output_0_49 */
    node[65]->input.tensors[0] = node[64]->output.tensors[0];
    node[65]->input.tensors[1] = const_tensor[87]; /* data_a */

    /* conv_4/model/3/project/conv/Conv_output_0_43 */
    node[66]->input.tensors[0] = node[65]->output.tensors[0];
    node[66]->input.tensors[1] = const_tensor[88]; /* data_weight */
    node[66]->input.tensors[2] = const_tensor[89]; /* data_bias */

    /* conv_4/model/3/Add_output_0_38 */
    node[67]->input.tensors[0] = node[61]->output.tensors[0];
    node[67]->input.tensors[1] = node[66]->output.tensors[0];

    /* conv_4/model/4/conv/conv/Conv_output_0_58 */
    node[68]->input.tensors[0] = node[67]->output.tensors[0];
    node[68]->input.tensors[1] = const_tensor[90]; /* data_weight */
    node[68]->input.tensors[2] = const_tensor[91]; /* data_bias */

    /* conv_4/model/4/conv/prelu/PRelu_output_0_57 */
    node[69]->input.tensors[0] = node[68]->output.tensors[0];
    node[69]->input.tensors[1] = const_tensor[92]; /* data_a */

    /* conv_4/model/4/conv_dw/conv/Conv_output_0_50 */
    node[70]->input.tensors[0] = node[69]->output.tensors[0];
    node[70]->input.tensors[1] = const_tensor[93]; /* data_weight */
    node[70]->input.tensors[2] = const_tensor[94]; /* data_bias */

    /* conv_4/model/4/conv_dw/prelu/PRelu_output_0_44 */
    node[71]->input.tensors[0] = node[70]->output.tensors[0];
    node[71]->input.tensors[1] = const_tensor[95]; /* data_a */

    /* conv_4/model/4/project/conv/Conv_output_0_39 */
    node[72]->input.tensors[0] = node[71]->output.tensors[0];
    node[72]->input.tensors[1] = const_tensor[96]; /* data_weight */
    node[72]->input.tensors[2] = const_tensor[97]; /* data_bias */

    /* conv_4/model/4/Add_output_0_35 */
    node[73]->input.tensors[0] = node[67]->output.tensors[0];
    node[73]->input.tensors[1] = node[72]->output.tensors[0];

    /* conv_4/model/5/conv/conv/Conv_output_0_52 */
    node[74]->input.tensors[0] = node[73]->output.tensors[0];
    node[74]->input.tensors[1] = const_tensor[98]; /* data_weight */
    node[74]->input.tensors[2] = const_tensor[99]; /* data_bias */

    /* conv_4/model/5/conv/prelu/PRelu_output_0_51 */
    node[75]->input.tensors[0] = node[74]->output.tensors[0];
    node[75]->input.tensors[1] = const_tensor[100]; /* data_a */

    /* conv_4/model/5/conv_dw/conv/Conv_output_0_45 */
    node[76]->input.tensors[0] = node[75]->output.tensors[0];
    node[76]->input.tensors[1] = const_tensor[101]; /* data_weight */
    node[76]->input.tensors[2] = const_tensor[102]; /* data_bias */

    /* conv_4/model/5/conv_dw/prelu/PRelu_output_0_40 */
    node[77]->input.tensors[0] = node[76]->output.tensors[0];
    node[77]->input.tensors[1] = const_tensor[103]; /* data_a */

    /* conv_4/model/5/project/conv/Conv_output_0_36 */
    node[78]->input.tensors[0] = node[77]->output.tensors[0];
    node[78]->input.tensors[1] = const_tensor[104]; /* data_weight */
    node[78]->input.tensors[2] = const_tensor[105]; /* data_bias */

    /* conv_4/model/5/se_module/avg_pool/GlobalAveragePool_output_0_46 */
    node[79]->input.tensors[0] = node[78]->output.tensors[0];

    /* conv_4/model/5/se_module/fc1/Conv_output_0_41 */
    node[80]->input.tensors[0] = node[79]->output.tensors[0];
    node[80]->input.tensors[1] = const_tensor[106]; /* data_weight */
    node[80]->input.tensors[2] = const_tensor[107]; /* data_bias */

    /* conv_4/model/5/se_module/relu/Relu_output_0_37 */
    node[81]->input.tensors[0] = node[80]->output.tensors[0];

    /* conv_4/model/5/se_module/fc2/Conv_output_0_34 */
    node[82]->input.tensors[0] = node[81]->output.tensors[0];
    node[82]->input.tensors[1] = const_tensor[108]; /* data_weight */
    node[82]->input.tensors[2] = const_tensor[109]; /* data_bias */

    /* conv_4/model/5/se_module/sigmoid/Sigmoid_output_0_33 */
    node[83]->input.tensors[0] = node[82]->output.tensors[0];

    /* conv_4/model/5/se_module/Mul_output_0_32 */
    node[84]->input.tensors[0] = node[78]->output.tensors[0];
    node[84]->input.tensors[1] = node[83]->output.tensors[0];

    /* conv_4/model/5/Add_output_0_31 */
    node[85]->input.tensors[0] = node[73]->output.tensors[0];
    node[85]->input.tensors[1] = node[84]->output.tensors[0];

    /* conv_45/conv/conv/Conv_output_0_27 */
    node[86]->input.tensors[0] = node[85]->output.tensors[0];
    node[86]->input.tensors[1] = const_tensor[110]; /* data_weight */
    node[86]->input.tensors[2] = const_tensor[111]; /* data_bias */

    /* conv_45/conv/prelu/PRelu_output_0_23 */
    node[87]->input.tensors[0] = node[86]->output.tensors[0];
    node[87]->input.tensors[1] = const_tensor[112]; /* data_a */

    /* conv_45/conv_dw/conv/Conv_output_0_19 */
    node[88]->input.tensors[0] = node[87]->output.tensors[0];
    node[88]->input.tensors[1] = const_tensor[113]; /* data_weight */
    node[88]->input.tensors[2] = const_tensor[114]; /* data_bias */

    /* conv_45/conv_dw/prelu/PRelu_output_0_15 */
    node[89]->input.tensors[0] = node[88]->output.tensors[0];
    node[89]->input.tensors[1] = const_tensor[115]; /* data_a */

    /* conv_45/project/conv/Conv_output_0_11 */
    node[90]->input.tensors[0] = node[89]->output.tensors[0];
    node[90]->input.tensors[1] = const_tensor[116]; /* data_weight */
    node[90]->input.tensors[2] = const_tensor[117]; /* data_bias */

    /* conv_5/model/0/conv/conv/Conv_output_0_28 */
    node[91]->input.tensors[0] = node[90]->output.tensors[0];
    node[91]->input.tensors[1] = const_tensor[118]; /* data_weight */
    node[91]->input.tensors[2] = const_tensor[119]; /* data_bias */

    /* conv_5/model/0/conv/prelu/PRelu_output_0_24 */
    node[92]->input.tensors[0] = node[91]->output.tensors[0];
    node[92]->input.tensors[1] = const_tensor[120]; /* data_a */

    /* conv_5/model/0/conv_dw/conv/Conv_output_0_20 */
    node[93]->input.tensors[0] = node[92]->output.tensors[0];
    node[93]->input.tensors[1] = const_tensor[121]; /* data_weight */
    node[93]->input.tensors[2] = const_tensor[122]; /* data_bias */

    /* conv_5/model/0/conv_dw/prelu/PRelu_output_0_16 */
    node[94]->input.tensors[0] = node[93]->output.tensors[0];
    node[94]->input.tensors[1] = const_tensor[123]; /* data_a */

    /* conv_5/model/0/project/conv/Conv_output_0_12 */
    node[95]->input.tensors[0] = node[94]->output.tensors[0];
    node[95]->input.tensors[1] = const_tensor[124]; /* data_weight */
    node[95]->input.tensors[2] = const_tensor[125]; /* data_bias */

    /* conv_5/model/0/Add_output_0_9 */
    node[96]->input.tensors[0] = node[90]->output.tensors[0];
    node[96]->input.tensors[1] = node[95]->output.tensors[0];

    /* conv_5/model/1/conv/conv/Conv_output_0_29 */
    node[97]->input.tensors[0] = node[96]->output.tensors[0];
    node[97]->input.tensors[1] = const_tensor[126]; /* data_weight */
    node[97]->input.tensors[2] = const_tensor[127]; /* data_bias */

    /* conv_5/model/1/conv/prelu/PRelu_output_0_25 */
    node[98]->input.tensors[0] = node[97]->output.tensors[0];
    node[98]->input.tensors[1] = const_tensor[128]; /* data_a */

    /* conv_5/model/1/conv_dw/conv/Conv_output_0_21 */
    node[99]->input.tensors[0] = node[98]->output.tensors[0];
    node[99]->input.tensors[1] = const_tensor[129]; /* data_weight */
    node[99]->input.tensors[2] = const_tensor[130]; /* data_bias */

    /* conv_5/model/1/conv_dw/prelu/PRelu_output_0_17 */
    node[100]->input.tensors[0] = node[99]->output.tensors[0];
    node[100]->input.tensors[1] = const_tensor[131]; /* data_a */

    /* conv_5/model/1/project/conv/Conv_output_0_13 */
    node[101]->input.tensors[0] = node[100]->output.tensors[0];
    node[101]->input.tensors[1] = const_tensor[132]; /* data_weight */
    node[101]->input.tensors[2] = const_tensor[133]; /* data_bias */

    /* conv_5/model/1/se_module/avg_pool/GlobalAveragePool_output_0_30 */
    node[102]->input.tensors[0] = node[101]->output.tensors[0];

    /* conv_5/model/1/se_module/fc1/Conv_output_0_26 */
    node[103]->input.tensors[0] = node[102]->output.tensors[0];
    node[103]->input.tensors[1] = const_tensor[134]; /* data_weight */
    node[103]->input.tensors[2] = const_tensor[135]; /* data_bias */

    /* conv_5/model/1/se_module/relu/Relu_output_0_22 */
    node[104]->input.tensors[0] = node[103]->output.tensors[0];

    /* conv_5/model/1/se_module/fc2/Conv_output_0_18 */
    node[105]->input.tensors[0] = node[104]->output.tensors[0];
    node[105]->input.tensors[1] = const_tensor[136]; /* data_weight */
    node[105]->input.tensors[2] = const_tensor[137]; /* data_bias */

    /* conv_5/model/1/se_module/sigmoid/Sigmoid_output_0_14 */
    node[106]->input.tensors[0] = node[105]->output.tensors[0];

    /* conv_5/model/1/se_module/Mul_output_0_10 */
    node[107]->input.tensors[0] = node[101]->output.tensors[0];
    node[107]->input.tensors[1] = node[106]->output.tensors[0];

    /* conv_5/model/1/Add_output_0_8 */
    node[108]->input.tensors[0] = node[96]->output.tensors[0];
    node[108]->input.tensors[1] = node[107]->output.tensors[0];

    /* conv_6_sep/conv/Conv_output_0_7 */
    node[109]->input.tensors[0] = node[108]->output.tensors[0];
    node[109]->input.tensors[1] = const_tensor[138]; /* data_weight */
    node[109]->input.tensors[2] = const_tensor[139]; /* data_bias */

    /* conv_6_sep/prelu/PRelu_output_0_6 */
    node[110]->input.tensors[0] = node[109]->output.tensors[0];
    node[110]->input.tensors[1] = const_tensor[140]; /* data_a */

    /* conv_6_dw/conv/Conv_output_0_5 */
    node[111]->input.tensors[0] = node[110]->output.tensors[0];
    node[111]->input.tensors[1] = const_tensor[141]; /* data_weight */
    node[111]->input.tensors[2] = const_tensor[142]; /* data_bias */

    /* conv_6_flatten/Reshape_output_0_4 */
    node[112]->input.tensors[0] = node[111]->output.tensors[0];

    /* linear/MatMul_output_0_3 */
    node[113]->input.tensors[0] = node[112]->output.tensors[0];
    node[113]->input.tensors[1] = const_tensor[143]; /* data_weight */
    node[113]->input.tensors[2] = const_tensor[144]; /* data_bias */

    /* output_1 */
    node[114]->input.tensors[0] = node[113]->output.tensors[0];
    node[114]->input.tensors[1] = const_tensor[145]; /* data_weight */
    node[114]->input.tensors[2] = const_tensor[146]; /* data_bias */


    }
    else
    {
    node[0]->output.tensors[0] = norm_tensor[0];
    node[0]->input.tensors[0] = norm_tensor[1];

    }
    graph->output.tensors[0] = norm_tensor[0];
    graph->input.tensors[0] = norm_tensor[1];


    if( enable_pre_post_process )
    {
        sort = TRUE;
        if( pre_process_map_count > 0 )
        {
            for( i = 0; i < pre_process_map_count; i++ )
            {
                status = vsi_nn_AddGraphPreProcess(graph, pre_process_map[i].graph_input_idx,
                                                   pre_process_map[i].preprocesses,
                                                   pre_process_map[i].preprocess_count);
                TEST_CHECK_STATUS( status, error );
            }
        }

        if( post_process_map_count > 0 )
        {
            for( i = 0; i < post_process_map_count; i++ )
            {
                 status = vsi_nn_AddGraphPostProcess(graph, post_process_map[i].graph_output_idx,
                                                     post_process_map[i].postprocesses,
                                                     post_process_map[i].postprocess_count);
                 TEST_CHECK_STATUS( status, error );
            }
        }
    }

    status = vsi_nn_SetupGraph( graph, sort );
    TEST_CHECK_STATUS( status, error );


    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vsi_nn_DumpGraphToJson( graph );
    vnn_ReleaseMinifasnetv1se( graph, release_ctx );

    return NULL;
} /* vsi_nn_CreateMinifasnetv1se() */

void vnn_ReleaseMinifasnetv1se
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vsi_nn_ReleaseMinifasnetv1se() */

