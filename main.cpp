/****************************************************************************
*   Generated by ACUITY 6.21.1
*   Match ovxlib 1.1.30
*
*   Neural Network application project entry file
****************************************************************************/
/*-------------------------------------------
                Includes
-------------------------------------------*/
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <fstream>
#ifdef __linux__
#include <time.h>
#include <inttypes.h>
#elif defined(_WIN32)
#include <windows.h>
#endif

#define _BASETSD_H

extern "C" {
#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_pre_process.h"
#include "vnn_facedetector3uint8.h"
#include "vnn_resnet34fp16.h"
}

#include "vnn_post_process.hpp"
#include <opencv2/opencv.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/videoio.hpp>

#include <pthread.h>

#include <mqtt.h>
#include "templates/posix_sockets.h"

/*-------------------------------------------
        Macros and Variables
-------------------------------------------*/
#ifdef __linux__
#define VSI_UINT64_SPECIFIER PRIu64
#elif defined(_WIN32)
#define VSI_UINT64_SPECIFIER "I64u"
#endif

static float psmsVal, psusVal;
static uint64_t st, frames; // for FPS stat
std::string dirFile = "./FaceData/ResNet34/";
std::string idFile = "itri-id.txt";
std::string dataFile = "itri_data.csv";
std::string csv_filepath = dirFile + dataFile;
std::string id_file_path = dirFile + idFile;
std::vector<cv::Mat> croppedimg;

const int FRC_input_size = 160;
const int FRC_feature_size = 128;
const float OPT_thrshold=0.7; //建議使用固定的thresh
int catched = 0;

#define DETECT_DEBUG 1
#define ITRI_SW_VERSION "20241204.003"

#define DETECT_RESULT_IMPL 0

/*-------------------------------------------
                  Functions Prototype
-------------------------------------------*/
/**
 * @brief The function that would be called whenever a PUBLISH is received.
 *
 * @note This function is not used in this example.
 */
void publish_callback(void** unused, struct mqtt_response_publish *published);

/**
 * @brief The client's refresher. This function triggers back-end routines to
 *        handle ingress/egress traffic to the broker.
 *
 * @note All this function needs to do is call \ref __mqtt_recv and
 *       \ref __mqtt_send every so often. I've picked 100 ms meaning that
 *       client ingress/egress traffic will be handled every 100 ms.
 */
void* client_refresher(void* client);

/**
 * @brief Safelty closes the \p sockfd and cancels the \p client_daemon before \c exit.
 */
void exit_example(int status, int sockfd, pthread_t *client_daemon);


/*-------------------------------------------
                  Functions
-------------------------------------------*/
#define BILLION 1000000000
uint64_t now()
{
#if defined(__linux__) || defined(__ANDROID__) || defined(__QNX__) || defined(__CYGWIN__)
        struct timespec ts;

        clock_gettime(CLOCK_MONOTONIC, &ts);

        return (uint64_t)((uint64_t)ts.tv_nsec + (uint64_t)ts.tv_sec * BILLION);
#elif defined(_WIN32) || defined(UNDER_CE)
        LARGE_INTEGER ln;

        QueryPerformanceCounter(&ln);

        return (uint64_t)ln.QuadPart;
#endif
}

//Add by yingwei
void draw_bounding_boxes(cv::Mat &image, const std::vector<FaceObject>& faces) {
    static std::vector<cv::Scalar> colors;
    static bool colors_initialized = false;

    if (!colors_initialized) {
        cv::RNG rng(time(0));
        for (int i = 0; i < 100; ++i) {
            int r = rng.uniform(0, 256);
            int g = rng.uniform(0, 256);
            int b = rng.uniform(0, 256);
            colors.emplace_back(b, g, r);
        }
        colors_initialized = true;
    }

    for (size_t i = 0; i < faces.size(); ++i) {
        const auto& face = faces[i];    

        int x1 = std::max(0, std::min(face.rect.x, image.cols - 1));
        int y1 = std::max(0, std::min(face.rect.y, image.rows - 1));
        int x2 = std::max(0, std::min(face.rect.width, image.cols - 1));
        int y2 = std::max(0, std::min(face.rect.height, image.rows - 1));        
        
        // ensure does not go out of range
        cv::Scalar color = colors[i % colors.size()];
        cv::rectangle(image, cv::Point(x1, y1), cv::Point(x2, y2), color, 2);

        std::string score_text = "Score: " + std::to_string(face.score);
        cv::putText(image, score_text, cv::Point(x1, y1 - 10), cv::FONT_HERSHEY_SIMPLEX, 0.6, color, 1);                      

        // display the name based on ResNet-34 result
        std::string name_text = face.name.empty() ? "Unknown" : face.name;

        int baseline = 0;
        cv::Size text_size = cv::getTextSize(name_text, cv::FONT_HERSHEY_SIMPLEX, 0.6, 2, &baseline);

        int x_text = x2 - text_size.width - 10;
        int y_text = y1 + text_size.height + 5;

        cv::putText(image, name_text, cv::Point(x_text, y_text), cv::FONT_HERSHEY_SIMPLEX, 0.6, color, 2);               
    }
}
//End by yingwei

static void vnn_ReleaseNeuralNetwork
    (
    vsi_nn_graph_t *graph
    )
{
    vnn_ReleaseFacedetector3Uint8( graph, TRUE );
    if (vnn_UseImagePreprocessNode())
    {
        vnn_ReleaseBufferImage();
    }
}

//Add by yingwei for integration, 20241108
static void vnn_ReleaseNeuralNetworkResnet34
    (
    vsi_nn_graph_t *graph
    )
{
    vnn_ReleaseResnet34Fp16( graph, TRUE );
    if (vnn_UseImagePreprocessNode())
    {
        vnn_ReleaseBufferImage();
    }
}
//End by yingwei for integration, 20241108

static vsi_status vnn_PostProcessNeuralNetwork
    (
    vsi_nn_graph_t *graph,
    std::vector<FaceObject>& faces
    )
{
    return vnn_PostProcessFacedetector3Uint8( graph, faces );
}

//Add by yingwei for integration, 20241108
static vsi_status vnn_PostProcessNeuralNetworkResnet34
    (
    vsi_nn_graph_t *graph,
    cv::Mat &original_image,
    FaceObject& face,
    const std::vector<std::vector<float>>& itriDataDataset,
    const std::vector<float>& featureNormList,
    const std::vector<std::string>& names
    )
{
    return vnn_PostProcessResnet34Fp16(graph, original_image, face, itriDataDataset, featureNormList, names);
}
//End by yingwei for integration, 20241108

#define BILLION                                 1000000000
static uint64_t get_perf_count()
{
#if defined(__linux__) || defined(__ANDROID__) || defined(__QNX__) || defined(__CYGWIN__)
    struct timespec ts;

    clock_gettime(CLOCK_MONOTONIC, &ts);

    return (uint64_t)((uint64_t)ts.tv_nsec + (uint64_t)ts.tv_sec * BILLION);
#elif defined(_WIN32) || defined(UNDER_CE)
    LARGE_INTEGER freq;
    LARGE_INTEGER ln;

    QueryPerformanceFrequency(&freq);
    QueryPerformanceCounter(&ln);

    return (uint64_t)(ln.QuadPart * BILLION / freq.QuadPart);
#endif
}

static vsi_status vnn_VerifyGraph
    (
    vsi_nn_graph_t *graph
    )
{
    vsi_status status = VSI_FAILURE;
    uint64_t tmsStart, tmsEnd, msVal, usVal;

    /* Verify graph */
    printf("Verify...\n");
    tmsStart = get_perf_count();
    status = vsi_nn_VerifyGraph( graph );
    TEST_CHECK_STATUS(status, final);
    tmsEnd = get_perf_count();
    msVal = (tmsEnd - tmsStart)/1000000;
    usVal = (tmsEnd - tmsStart)/1000;
    printf("Verify Graph: %"VSI_UINT64_SPECIFIER"ms or %"VSI_UINT64_SPECIFIER"us\n", msVal, usVal);

final:
    return status;
}

static vsi_status vnn_ProcessGraph
    (
    vsi_nn_graph_t *graph
    )
{
    vsi_status status = VSI_FAILURE;
    int32_t i,loop;
    char *loop_s;
    uint64_t tmsStart, tmsEnd, sigStart, sigEnd;
    float msVal, usVal;

    status = VSI_FAILURE;
    loop = 1; /* default loop time is 1 */
    loop_s = getenv("VNN_LOOP_TIME");
    if(loop_s)
    {
        loop = atoi(loop_s);
    }

    /* Run graph */
    tmsStart = get_perf_count();
    printf("Start run graph [%d] times...\n", loop);
    for(i = 0; i < loop; i++)
    {
        sigStart = get_perf_count();
#ifdef VNN_APP_ASYNC_RUN
        status = vsi_nn_AsyncRunGraph( graph );
        if(status != VSI_SUCCESS)
        {
            printf("Async Run graph the %d time fail\n", i);
        }
        TEST_CHECK_STATUS( status, final );

        //do something here...

        status = vsi_nn_AsyncRunWait( graph );
        if(status != VSI_SUCCESS)
        {
            printf("Wait graph the %d time fail\n", i);
        }
#else
        status = vsi_nn_RunGraph( graph );
        if(status != VSI_SUCCESS)
        {
            printf("Run graph the %d time fail\n", i);
        }
#endif
        TEST_CHECK_STATUS( status, final );

        sigEnd = get_perf_count();
        msVal = (sigEnd - sigStart)/(float)1000000;
        usVal = (sigEnd - sigStart)/(float)1000;
        //printf("Run the %u time: %.2fms or %.2fus\n", (i + 1), msVal, usVal);
    }
    tmsEnd = get_perf_count();
    msVal = (tmsEnd - tmsStart)/(float)1000000;
    usVal = (tmsEnd - tmsStart)/(float)1000;
    printf("vxProcessGraph execution time:\n");
    printf("Total   %.2fms or %.2fus\n", msVal, usVal);
    //printf("Average %.2fms or %.2fus\n", ((float)usVal)/1000/loop, ((float)usVal)/loop);
    psmsVal = msVal;
    psusVal = usVal;

final:
    return status;
}

static vsi_status vnn_PreProcessNeuralNetwork
    (
    vsi_nn_graph_t *graph,
    int argc,
    char **argv,
    uint8_t* rgbData    
    )
{
    /*
     * argv0:   execute file
     * argv1:   data file
     * argv2~n: inputs n file
     */
    const char **inputs = (const char **)argv + 2;
    uint32_t input_num = argc - 2;

    return vnn_PreProcessFacedetector3Uint8( graph, inputs, input_num, rgbData );
}

//Add by yingwei for integration, 20241108
static vsi_status vnn_PreProcessNeuralNetworkResnet34
    (
    vsi_nn_graph_t *graph,
    int argc,
    char **argv,
    float* rgbData    
    )
{
    /*
     * argv0:   execute file
     * argv1:   data file
     * argv2~n: inputs n file
     */
    const char **inputs = (const char **)argv + 2;
    uint32_t input_num = argc - 2;
    
    return vnn_PreProcessResnet34Fp16( graph, inputs, input_num, rgbData );
}
//End by yingwei for integration, 20241108

static vsi_nn_graph_t *vnn_CreateNeuralNetwork
    (
    const char *data_file_name
    )
{
    vsi_nn_graph_t *graph = NULL;
    uint64_t tmsStart, tmsEnd, msVal, usVal;

    tmsStart = get_perf_count();
    graph = vnn_CreateFacedetector3Uint8( data_file_name, NULL,
                      vnn_GetPreProcessMap(), vnn_GetPreProcessMapCount(),
                      vnn_GetPostProcessMap(), vnn_GetPostProcessMapCount() );
    TEST_CHECK_PTR(graph, final);

    tmsEnd = get_perf_count();
    msVal = (tmsEnd - tmsStart)/1000000;
    usVal = (tmsEnd - tmsStart)/1000;
    printf("Create Neural Network: %"VSI_UINT64_SPECIFIER"ms or %"VSI_UINT64_SPECIFIER"us\n", msVal, usVal);

final:
    return graph;
}

//Add by yingwei for integration, 20241108
static vsi_nn_graph_t *vnn_CreateNeuralNetworkResnet34
    (
    const char *data_file_name
    )
{
    vsi_nn_graph_t *graph = NULL;
    uint64_t tmsStart, tmsEnd, msVal, usVal;

    tmsStart = get_perf_count();
    graph = vnn_CreateResnet34Fp16( data_file_name, NULL,
                      vnn_GetPreProcessMap(), vnn_GetPreProcessMapCount(),
                      vnn_GetPostProcessMap(), vnn_GetPostProcessMapCount() );
    TEST_CHECK_PTR(graph, final);

    tmsEnd = get_perf_count();
    msVal = (tmsEnd - tmsStart)/1000000;
    usVal = (tmsEnd - tmsStart)/1000;
    printf("Create Neural Network: %"VSI_UINT64_SPECIFIER"ms or %"VSI_UINT64_SPECIFIER"us\n", msVal, usVal);

final:
    return graph;
}
//End by yingwei for integration, 20241108

//Convert image data to array
int Mat_to_array(const cv::Mat input, uint8_t* pRgb)
{
    int height = input.rows;
    int width = input.cols;

    for (int i = 0;i < height;i++)
    {
	for (int j = 0;j < width;j++)
	{
            for (int k = 0;k < 3;k++)
            {
	        pRgb[i * width * 3 + j * 3 + k] = input.at<cv::Vec3b>(i, j)[k];
	    }
	}
    }
    return 0;
}

//add by yingwei
int Mat_to_array_resnet34(const cv::Mat& input, float* pRgb) {
    int height = input.rows;
    int width = input.cols;

    for (int i = 0; i < height; i++) {
        for (int j = 0; j < width; j++) {
            pRgb[i * width + j] = input.at<uint8_t>(i, j) / 255.0f;
        }
    }
    return 0;
}

cv::Mat extractFaceImage(const cv::Mat& image, const cv::Rect& face) 
{
    int x1 = std::max(0, std::min(face.x, image.cols - 1));
    int y1 = std::max(0, std::min(face.y, image.rows - 1));
    int x2 = std::max(0, std::min(face.width, image.cols - 1));
    int y2 = std::max(0, std::min(face.height, image.rows - 1));

    // face region cropping
    cv::Rect roi(x1, y1, x2 - x1, y2 - y1);
    cv::Mat face_img = image(roi);

    return face_img;
}

float database_norm(const std::vector<float>& data) {
    float sum = 0.0;
    for (float value : data) {
        sum += value * value;
    }
    return sum;
}

//std::vector<float> load_and_compute_norms(const std::string& dirFile, const std::string& idFile, const std::string& dataFile, int FRC_input_size) 
void load_and_compute_norms(const std::string& dirFile, const std::string& idFile, const std::string& dataFile, int FRC_input_size,
                            std::vector<std::vector<float>>& itriDataDataset, std::vector<float>& featureNormList, std::vector<std::string>& names)
{    
    // read itri-id.txt
    std::ifstream idFileStream(dirFile + idFile);
    if (!idFileStream.is_open()) {
        throw std::runtime_error("Unable to open file: " + dirFile + idFile);
    }

    std::vector<int> ids;

    std::string line;
    while (std::getline(idFileStream, line)) {
        std::stringstream ss(line);
        std::string name;
        int id;

        std::getline(ss, name, ',');
        ss >> id;

        names.push_back(name);
        //ids.push_back(id);
    }
    idFileStream.close();

    // read itri_data.csv
    std::ifstream dataFileStream(dirFile + dataFile);
    if (!dataFileStream.is_open()) {
        throw std::runtime_error("Unable to open file: " + dirFile + dataFile);
    }

    while (std::getline(dataFileStream, line)) {
        std::stringstream ss(line);
        std::string value;
        std::vector<float> row;

        while (std::getline(ss, value, ',')) {
            row.push_back(std::stof(value));
        }
        itriDataDataset.push_back(row);
    }
    dataFileStream.close();

    // 計算範數
    for (const auto& row : itriDataDataset) {
        std::vector<float> Data_F(row.begin(), row.begin() + FRC_input_size);
        float Data_Norm = database_norm(Data_F);
        featureNormList.push_back(Data_Norm);
    }

    return;
}

static int globalMaxId = 0;
int registerNewPerson(const std::string& filepath, const std::string& pname) {
    std::ifstream infile(filepath);
    if (!infile.is_open()) {
        std::cerr << "Failed to open file " << filepath << std::endl;
        return -1;
    }

    std::string line;
    int localMaxId = -1;

    while (std::getline(infile, line)) {
        std::stringstream ss(line);
        std::string name;
        int id;
        if (std::getline(ss, name, ',') && ss >> id) {
            localMaxId = std::max(localMaxId, id);
        }
    }

    infile.close();

    // update global max id
    globalMaxId = std::max(globalMaxId, localMaxId);

    int newId = ++globalMaxId;

    // output name + id
    std::string new_entry = pname + "," + std::to_string(newId);

    std::ofstream outfile(filepath, std::ios::app);
    if (!outfile.is_open()) {
        std::cerr << "Failed to open file for writing: " << filepath << std::endl;
        return -1;
    }

    outfile << new_entry << std::endl;
    outfile.close();

    std::cout << "New person registered: " << new_entry << std::endl;

    return newId;
}

void append_to_csv_with_id(const std::string& csv_filepath, const std::vector<float>& tensor_features, int newId) {
    std::ofstream csv_file(csv_filepath, std::ios::app);
    if (!csv_file.is_open()) {
        std::cerr << "Failed to open CSV file for appending: " << csv_filepath << std::endl;
        return;
    }

    bool first = true;

    for (const auto& feature : tensor_features) {
        if (!first) {
            csv_file << ",";
        }

        csv_file << std::scientific << std::setprecision(6) << feature;
        first = false;
    }

    // write newId
    csv_file << "," << newId << std::endl;

    csv_file.close();
    std::cout << "Data appended to CSV file: " << csv_filepath << std::endl;
}

std::vector<float> extract_tensor_features(vsi_nn_graph_t* graph) 
{
    // 1. get tensor 
    vsi_nn_tensor_t *features_tensor = vsi_nn_GetTensor(graph, graph->output.tensors[0]);
    
    if (!features_tensor) 
    {
        std::cerr << "Failed to get tensor from graph." << std::endl;
        return {};
    }

    // 2. get tensor size
    vsi_size_t sz_features = 1;
    for (uint32_t i = 0; i < features_tensor->attr.dim_num; i++) 
    {
        sz_features *= features_tensor->attr.size[i];
    }

    // 3. get stride
    vsi_size_t stride_features = (vsi_size_t)vsi_nn_TypeGetBytes(features_tensor->attr.dtype.vx_type);
    if (stride_features == 0) stride_features = sizeof(float);

    int num_features = sz_features / stride_features;

    // 4. convert tensor to float32
    float* tensor_features_data = vsi_nn_ConvertTensorToFloat32Data(graph, features_tensor);
    
    if (!tensor_features_data) 
    {
        std::cerr << "Failed to convert tensor to float32 data." << std::endl;
        return {};
    }

    return std::vector<float>(tensor_features_data, tensor_features_data + sz_features);
}

std::string generateUniqueFilename(const std::string& dir, const std::string& baseName) {
    std::string filename;
    int count = 0;

    while (true) 
    {
        filename = dir + "/" + baseName + "_" + std::to_string(count++) + ".jpg";
        std::ifstream file(filename);
        if (!file.is_open()) 
        {
            break;
        }
    }

    return filename;
}
//end by yingwei
/*-------------------------------------------
                  Main Functions
-------------------------------------------*/
//
#if 1
int main(int argc, char** argv) 
{
    vsi_status status = VSI_FAILURE;
    vsi_status statusResnet34 = VSI_FAILURE;
    vsi_nn_graph_t* graph = nullptr;
    vsi_nn_graph_t* graphResnet34 = nullptr;
    vsi_nn_graph_t* graphMiniFasNetV1SE = nullptr;
    vsi_nn_graph_t* graphMiniFasNetV2 = nullptr;

    const char* data_name = nullptr;
    const char* data_name_resnet34 = nullptr;
    cv::VideoCapture cap;
    char *rearv[3];
    int cmd_op = 0;
    char cmd_opl;
    std::string pname;
    std::string fname; 

    if (argc < 3) {
        std::cerr << "Usage: " << argv[0] << " data_file" << std::endl;
        return -1;
    }

    data_name = argv[1];

    //add ted for recongnition and register image command, 20241115
#if 1 
    for (int z = 0; z < 3; z++)
        rearv[z] = argv[z];

    while(true) 
    {
        cmd_op = getopt(argc, argv, "r:R");
        if (cmd_op == -1)
            break;

        switch (cmd_op) 
        {
            case 'r':
                printf("command option: -%c, option argument: %s\n", cmd_op, optarg);
                cmd_opl = 'r';
                pname.assign(optarg);
                break;
            case 'R':
                printf("command option: -%c\n", cmd_op);
                printf("option argument: %s\n", optarg);
                cmd_opl = 'R';
                break;
            case '?':
                printf("wrong option format: -%c\n", isprint(optopt)?optopt:'#');
                break;
                default:
                printf("default option\n");
                break;
        }
    }

    printf("cmd op: %d\n", cmd_op);
    if (cmd_opl == 'r') 
    {
        printf("register a person\n");
        printf("the person name is: %s\n", pname.c_str());    
        //fname = "./Face_capture/" + pname + ".jpg";
        fname = generateUniqueFilename("./Face_capture", pname);
        printf("person picture name: %s\n", fname.c_str());
        //isu = pthread_create(&t1, NULL, photowait, NULL);
        //if (isu != 0) {
                //printf("thread1 create failed!\n");
        //}
    }
    else if (cmd_opl == 'R') 
    {
	    printf("Recognize faces\n");
    }
    else 
    {
        printf("illegal condition\n");
	    return -1;
    }    
#endif      
    //end by ted    

    std::cout << "S/W Version : " << ITRI_SW_VERSION << std::endl;
    data_name_resnet34 = "network_binary_resnet34.nb";
    std::cout << "data_name: " << data_name << std::endl;
    std::cout << "data_name_resnet34: " << data_name_resnet34 << std::endl;    

    graph = vnn_CreateNeuralNetwork(data_name);
    graphResnet34 = vnn_CreateNeuralNetworkResnet34(data_name_resnet34);

    if (!graph) {
        std::cerr << "Failed to create neural network." << std::endl;
        return -1;
    }else if (!graphResnet34){
        std::cerr << "Failed to create ResNet34 neural network." << std::endl;
        return -1;
    }

    status = vnn_VerifyGraph(graph);
    statusResnet34 = vnn_VerifyGraph(graphResnet34);
    if (status != VSI_SUCCESS) {
        std::cerr << "Graph verification failed." << std::endl;
        vnn_ReleaseNeuralNetwork(graph);
        return -1;
    }else if (statusResnet34 != VSI_SUCCESS){
        std::cerr << "Graph(ResNet34) verification failed." << std::endl;
        vnn_ReleaseNeuralNetworkResnet34(graphResnet34);
        return -1;
    } 

    // 讀取和計算範數
    std::vector<std::vector<float>> itriDataDataset;
    std::vector<float> featureNorms;
    std::vector<std::string> names; 

    try 
    {
        load_and_compute_norms(dirFile, idFile, dataFile, FRC_input_size, itriDataDataset, featureNorms, names);
    } catch (const std::exception& e) {
        std::cerr << "Error: " << e.what() << std::endl;
        return -1;
    }           

    // open camera (0 : camera)
    cap.open(0);
    if (!cap.isOpened()) {
        std::cerr << "Failed to open camera." << std::endl;
        vnn_ReleaseNeuralNetwork(graph);
        return -1;
    }

    cv::Mat img;
    int pscount = 0;
    float psavgmsVal = 0;
    float psavgusVal = 0;
    while (true) {
        cap >> img;
        if (img.empty()) {
            std::cout << "Failed to read frame from camera." << std::endl;
            break;
        }

        cv::resize(img, img, cv::Size(IMAGE_WIDTH, IMAGE_HEIGHT));
        cv::cvtColor(img, img, cv::COLOR_BGR2RGB);

        uint8_t* pRgb = new uint8_t[img.rows * img.cols * 3];
        Mat_to_array(img, pRgb);

        //mod ted for recongnition and register image command, 20241115
        //status = vnn_PreProcessNeuralNetwork(graph, argc, argv, pRgb);
        status = vnn_PreProcessNeuralNetwork(graph, 3, rearv, pRgb);
        //end by ted
        if (status != VSI_SUCCESS) {
            std::cerr << "Pre-processing failed." << std::endl;
            delete[] pRgb;
            break;
        }

        status = vnn_ProcessGraph(graph);       
        if (status != VSI_SUCCESS) {
            std::cerr << "Graph processing failed." << std::endl;
            delete[] pRgb;
            break;
        }

        pscount = pscount + 1;
        if (pscount <= 100) {
            psavgmsVal = psavgmsVal + psmsVal;
            psavgusVal = psavgusVal + psusVal;
        }
        if (pscount == 100) {
            psavgmsVal = ((float)psavgmsVal)/100;
            psavgusVal = ((float)psavgusVal)/100;
            printf("All average process graph execution time: %.2fms or %.2fus\n", psavgmsVal, psavgusVal);
        }

        std::vector<FaceObject> faces;        
        status = vnn_PostProcessNeuralNetwork(graph, faces);       
        if (status != VSI_SUCCESS) {
            std::cerr << "Post-processing failed." << std::endl;
            delete[] pRgb;
            break;
        }

        //add ted for recongnition and register image command, 20241115
        printf("The number of faces: %zu\n", faces.size());
        if (cmd_opl == 'r') 
        {
            printf("register a new person\n");
            printf("wait to press 's' key to save a new person picture\n");
            cv::cvtColor(img, img, cv::COLOR_RGB2BGR);
            cv::imshow("Take photo", img);
            int key = cv::waitKey(1);

            if (key == 's' && faces.size() == 1) 
            {
                catched = 1;
            }else{                
                continue;
            }
        }
        else
            printf("Recognize faces\n");
        //end by ted        

        // For each detected face, process with ResNet-34
        std::vector<std::string> itri_name_list;

        for (auto& face : faces)
        {
            // 1. Scale và crop cho từng model
            cv::Rect rect_v2 = scale_and_clamp_bbox(face.rect, 2.7f, img.cols, img.rows);
            cv::Rect rect_v1se = scale_and_clamp_bbox(face.rect, 4.0f, img.cols, img.rows);

            cv::Mat face_img_v2 = extractFaceImage(img, rect_v2);
            cv::Mat face_img_v1se = extractFaceImage(img, rect_v1se);

            // 2. Resize về 80x80
            cv::resize(face_img_v2, face_img_v2, cv::Size(80, 80));
            cv::resize(face_img_v1se, face_img_v1se, cv::Size(80, 80));

            // 3. Chuyển ảnh sang mảng input cho model
            uint8_t input_v2[80*80*3];
            uint8_t input_v1se[80*80*3];
            Mat_to_array_anti_spoofing(face_img_v2, input_v2);
            Mat_to_array_anti_spoofing(face_img_v1se, input_v1se);

            uint8_t* input_v2_ptr = input_v2;
            uint8_t* input_v1se_ptr = input_v1se;
            // 4. Chạy MiniFASNetV2
            vnn_PreProcessMinifasnetv2(graphMiniFasNetV2, nullptr, 1, &input_v2_ptr);
            vnn_ProcessGraph(graphMiniFasNetV2);
            float raw_probs_v2[3];
            {
                vsi_nn_tensor_t *output_tensor = vsi_nn_GetTensor(graphMiniFasNetV2, graphMiniFasNetV2->output.tensors[0]);
                vsi_size_t sz = 0;
                float *raw_probs = get_output_probabilities(graphMiniFasNetV2, output_tensor, &sz);
                for (int i = 0; i < 3; ++i) raw_probs_v2[i] = raw_probs[i];
                free(raw_probs);
            }

            // 5. Chạy MiniFASNetV1SE
            vnn_PreProcessMinifasnetv1se(graphMiniFasNetV1SE, nullptr, 1, &input_v1se_ptr);
            vnn_ProcessGraph(graphMiniFasNetV1SE);
            float raw_probs_v1se[3];
            {
                vsi_nn_tensor_t *output_tensor = vsi_nn_GetTensor(graphMiniFasNetV1SE, graphMiniFasNetV1SE->output.tensors[0]);
                vsi_size_t sz = 0;
                float *raw_probs = get_output_probabilities(graphMiniFasNetV1SE, output_tensor, &sz);
                for (int i = 0; i < 3; ++i) raw_probs_v1se[i] = raw_probs[i];
                free(raw_probs);
            }

            // 6. Ensemble: cộng raw_probs lại chia đôi, rồi softmax lại (3 class)
            float probs_ensemble[3];
            for (int i = 0; i < 3; ++i)
                probs_ensemble[i] = (raw_probs_v2[i] + raw_probs_v1se[i]) / 2.0f;

            float probs_final[3];
            softmax(probs_ensemble, probs_final, 3);
            
            // 7. Quyết định spoofing/real/unknown
            int max_idx = 0;
            float max_prob = probs_final[0];
            for (int i = 1; i < 3; ++i) {
                if (probs_final[i] > max_prob) {
                    max_prob = probs_final[i];
                    max_idx = i;
                }
            }

                if (max_idx == 1) {
                // Pass anti-spoofing, tiếp tục nhận diện với ResNet34
                // Chuẩn bị ảnh khuôn mặt cho ResNet34 (ví dụ resize về 160x160)
                cv::Mat face_img_resnet;
                cv::resize(face_img_v2, face_img_resnet, cv::Size(FRC_input_size, FRC_input_size));
                // Chuyển ảnh sang mảng input cho ResNet34 nếu cần (tùy hàm preprocess)
                // Giả sử bạn có hàm Mat_to_array_resnet34
                float input_resnet[FRC_input_size * FRC_input_size * 3];
                Mat_to_array_resnet34(face_img_resnet, input_resnet);

                // Tiền xử lý và chạy ResNet34
                vnn_PreProcessResnet34Fp16(graphResnet34, nullptr, 1, input_resnet);
                vnn_ProcessGraph(graphResnet34);

                // Nhận diện: postprocess, so sánh với database, gán tên cho face
                vnn_PostProcessResnet34Fp16(graphResnet34, face_img_resnet, face, itriDataDataset, featureNorms, names);
            } else if (max_idx == 0) {
                face.name = "Spoof";
                continue;
            } else {
                face.name = "Unknown";
                continue;
            }
        }

        if (catched == 1)
        {
            //1. register new person
            //registerNewPerson("./FaceData/ResNet34/itri-id.txt", pname);        //update itri-id.txt 
            int newId = registerNewPerson(dirFile + idFile, pname);   //update itri-id.txt    

            //2. get resnet34 feature map
            std::vector<float> tensor_features = extract_tensor_features(graphResnet34);                        
            
            //3. write resnet34 feature map and ID to itri_data.csv
            append_to_csv_with_id(csv_filepath, tensor_features, newId);

            cv::imwrite(fname, croppedimg[0]);
            printf("save a new person picture successfully!\n");
            //croppedimg.clear();
            //delete[] pRgb;
            break;
        }       

        draw_bounding_boxes(img, faces);       
        cv::cvtColor(img, img, cv::COLOR_RGB2BGR);
        cv::imshow("Detected Faces", img);

        if (cv::waitKey(1) >= 0) break; // press any key to break       
        croppedimg.clear();
        delete[] pRgb;
    }

    cap.release();
    vnn_ReleaseNeuralNetwork(graph);

    return 0;
}
#else
/**
 * A simple program to that publishes the current time whenever ENTER is pressed.
 */
int main(int argc, const char *argv[])
{
    const char* addr;
    const char* port;
    const char* topic;

    /* get address (argv[1] if present) */
    if (argc > 1) {
        addr = argv[1];
    } else {
        addr = "test.mosquitto.org";
    }

    /* get port number (argv[2] if present) */
    if (argc > 2) {
        port = argv[2];
    } else {
        port = "1883";
    }

    /* get the topic name to publish */
    if (argc > 3) {
        topic = argv[3];
    } else {
        topic = "datetime";
    }

    /* open the non-blocking TCP socket (connecting to the broker) */
    int sockfd = open_nb_socket(addr, port);

    if (sockfd == -1) {
        perror("Failed to open socket: ");
        exit_example(EXIT_FAILURE, sockfd, NULL);
    }

    /* setup a client */
    struct mqtt_client client;
    uint8_t sendbuf[2048]; /* sendbuf should be large enough to hold multiple whole mqtt messages */
    uint8_t recvbuf[1024]; /* recvbuf should be large enough any whole mqtt message expected to be received */
    mqtt_init(&client, sockfd, sendbuf, sizeof(sendbuf), recvbuf, sizeof(recvbuf), publish_callback);
    /* Create an anonymous session */
    const char* client_id = NULL;
    /* Ensure we have a clean session */
    uint8_t connect_flags = MQTT_CONNECT_CLEAN_SESSION;
    /* Send connection request to the broker. */
    mqtt_connect(&client, client_id, NULL, NULL, 0, NULL, NULL, connect_flags, 400);

    /* check that we don't have any errors */
    if (client.error != MQTT_OK) {
        fprintf(stderr, "error: %s\n", mqtt_error_str(client.error));
        exit_example(EXIT_FAILURE, sockfd, NULL);
    }

    /* start a thread to refresh the client (handle egress and ingree client traffic) */
    pthread_t client_daemon;
    if(pthread_create(&client_daemon, NULL, client_refresher, &client)) {
        fprintf(stderr, "Failed to start client daemon.\n");
        exit_example(EXIT_FAILURE, sockfd, NULL);

    }

    /* start publishing the time */
    printf("%s is ready to begin publishing the time.\n", argv[0]);
    printf("Press ENTER to publish the current time.\n");
    printf("Press CTRL-D (or any other key) to exit.\n\n");
    while(fgetc(stdin) == '\n') {
        /* get the current time */
        time_t timer;
        time(&timer);
        struct tm* tm_info = localtime(&timer);
        char timebuf[26];
        strftime(timebuf, 26, "%Y-%m-%d %H:%M:%S", tm_info);

        /* print a message */
        char application_message[256];
        snprintf(application_message, sizeof(application_message), "The time is %s", timebuf);
        printf("%s published : \"%s\"", argv[0], application_message);

        /* publish the time */
        mqtt_publish(&client, topic, application_message, strlen(application_message) + 1, MQTT_PUBLISH_QOS_0);

        /* check for errors */
        if (client.error != MQTT_OK) {
            fprintf(stderr, "error: %s\n", mqtt_error_str(client.error));
            exit_example(EXIT_FAILURE, sockfd, &client_daemon);
        }
    }

    /* disconnect */
    printf("\n%s disconnecting from %s\n", argv[0], addr);
    sleep(1);

    /* exit */
    exit_example(EXIT_SUCCESS, sockfd, &client_daemon);
}

#endif

void exit_example(int status, int sockfd, pthread_t *client_daemon)
{
    if (sockfd != -1) close(sockfd);
    if (client_daemon != NULL) pthread_cancel(*client_daemon);
    exit(status);
}

void publish_callback(void** unused, struct mqtt_response_publish *published)
{
    /* not used in this example */
}

void* client_refresher(void* client)
{
    while(1)
    {
        mqtt_sync((struct mqtt_client*) client);
        usleep(100000U);
    }
    return NULL;
}
